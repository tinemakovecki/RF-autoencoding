% !TeX spellcheck = sl_SI
% vim: set spell spelllang=sl:
% za preverjanje črkovanja, če se uporablja Texstudio ali vim
\documentclass[12pt,a4paper,twoside]{article}
\usepackage[utf8]{inputenc}  % pravilno razpoznavanje unicode znakov

% NASLEDNJE UKAZE USTREZNO POPRAVI
\newcommand{\program}{Matematika} % ime studijskega programa
\newcommand{\imeavtorja}{Tine Makovecki} % ime avtorja
\newcommand{\imementorja}{prof.~dr.~Ljupčo Todorovski} % akademski naziv in ime mentorja, uporabi poln naziv, prof.~dr.~, doc.~dr., ali izr.~prof.~dr.
\newcommand{\imesomentorja}{} % akademski naziv in ime somentorja, če ga imate
\newcommand{\naslovdela}{Samokodirnik z naključnim gozdom}
\newcommand{\letnica}{2021} % letnica magistriranja
\newcommand{\opis}{Delo obravnava konstrukcijo samokodirnika na osnovi naključnega gozda.}  % Opis dela v eni povedi. Ne sme vsebovati matematičnih simbolov v $ $.
\newcommand{\kljucnebesede}{blib\sep blob} % ključne besede, ločene z \sep, da se PDF metapodatki prav procesirajo
\newcommand{\keywords}{blub\sep blob} % ključne besede v angleščini
\newcommand{\organization}{Univerza v Ljubljani, Fakulteta za matematiko in fiziko} % fakulteta
\newcommand{\literatura}{literatura}  % pot do datoteke z literaturo (brez .bib končnice)
\newcommand{\sep}{, }  % separator med ključnimi besedami v besedilu
% KONEC PODATKOV

\usepackage{bibentry}         % za navajanje literature v programu dela s celim imenom
\nobibliography{\literatura}
\newcommand{\plancite}[1]{\item[\cite{#1}] \bibentry{#1}} % citiranje v programu dela

\usepackage{filecontents}  % za pisanje datoteke s PDF metapodatki
\usepackage{silence} \WarningFilter{latex}{Overwriting file}  % odstrani annoying warning o obstoju datoteke
% datoteka s PDF metapodatki, zgenerira se kot magisterij.xmpdata
\begin{filecontents*}{\jobname.xmpdata}
  \Title{\naslovdela}
  \Author{\imeavtorja}
  \Keywords{\kljucnebesede}
  \Subject{matematika}
  \Org{\organization}
\end{filecontents*}

\usepackage[a-1b]{pdfx}  % zgenerira PDF v tem PDF/A-1b formatu, kot zahteva knjižnica
\hypersetup{bookmarksopen, bookmarksdepth=3, colorlinks=true,
  linkcolor=black, anchorcolor=black, citecolor=black, filecolor=black,
  menucolor=black, runcolor=black, urlcolor=black, pdfencoding=auto,
  breaklinks=true, psdextra}

\usepackage[slovene]{babel}  % slovenščina
\usepackage[T1]{fontenc}     % naprednejše kodiranje fonta
\usepackage{amsmath,amssymb,amsfonts,amsthm} % matematični paketi
\usepackage{graphicx}     % za slike
\usepackage{emptypage}    % prazne strani so neoštevilčene, ampak so štete
\usepackage{units}        % fizikalne enote kot \unit[12]{kg} s polovico nedeljivega presledka, glej primer v kodi
\usepackage{makeidx}      % za stvarno kazalo, lahko zakomentiraš, če ne rabiš
\makeindex                % za stvarno kazalo, lahko zakomentiraš, če ne rabiš
% oblika strani
\usepackage[
  top=3cm,
  bottom=3cm,
  inner=3.5cm,      % margini za dvostransko tiskanje
  outer=2.5cm,
  footskip=40pt     % pozicija številke strani
]{geometry}

% VEČ ZANIMIVIH PAKETOV
% \usepackage{array}      % več možnosti za tabele
% \usepackage[list=true,listformat=simple]{subcaption}  % več kot ena slika na figure, omogoči slika 1a, slika 1b
% \usepackage[all]{xy}    % diagrami
% \usepackage{doi}        % za clickable DOI entrye v bibliografiji
% \usepackage{enumerate}     % več možnosti za sezname

% Za barvanje source kode
% \usepackage{minted}
% \renewcommand\listingscaption{Program}

% Za pisanje psevdokode
\usepackage{algpseudocode}  % za psevdokodo
\usepackage{algorithm}
% \usepackage{algorithmic} % TODO: this might have to fuck off sadly
% TODO: urediti okolje za algoritme
% \floatname{algorithm}{Algoritem}
% \renewcommand{\listalgorithmname}{Kazalo algoritmov}

% DRUGI TVOJI PAKETI:
\usepackage{subfigure}

\setlength{\overfullrule}{50pt} % označi predlogo vrstico
\pagestyle{plain}               % samo številka strani na dnu, nobene glave / noge

% ukazi za matematična okolja
\theoremstyle{definition} % tekst napisan pokončno
\newtheorem{definicija}{Definicija}[section]
\newtheorem{primer}[definicija]{Primer}
\newtheorem{opomba}[definicija]{Opomba}
\newtheorem{aksiom}{Aksiom}

\theoremstyle{plain} % tekst napisan poševno
\newtheorem{lema}[definicija]{Lema}
\newtheorem{izrek}[definicija]{Izrek}
\newtheorem{trditev}[definicija]{Trditev}
\newtheorem{posledica}[definicija]{Posledica}

\numberwithin{equation}{section}  % števec za enačbe zgleda kot (2.7) in se resetira v vsakem poglavju

% Matematični ukazi
\newcommand{\R}{\mathbb R}
\newcommand{\N}{\mathbb N}
\newcommand{\Z}{\mathbb Z}
\renewcommand{\C}{\mathbb C}
\newcommand{\Q}{\mathbb Q}

% \DeclareMathOperator{\tr}{tr}  % morda potrebuješ operator za sled ali kaj drugega?

% bold matematika znotraj \textbf{ }, tudi v naslovih, kot \omega spodaj
\makeatletter \g@addto@macro\bfseries{\boldmath} \makeatother

% Poimenuj kazalo slik kot ``Kazalo slik'' in ne ``Slike''
\addto\captionsslovene{
  \renewcommand{\listfigurename}{Kazalo slik}%
}

% če želiš, da se poglavja začnejo na lihih straneh zgoraj
% \let\oldsection\section
% \def\section{\cleardoublepage\oldsection}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%           DOCUMENT           %%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\pagenumbering{roman} % začnemo z rimskimi številkami
\thispagestyle{empty} % ampak na prvi strani ni številke

\noindent{\large
UNIVERZA V LJUBLJANI\\[1mm]
FAKULTETA ZA MATEMATIKO IN FIZIKO\\[5mm]
\program\ -- 2.~stopnja}
% ustrezno dopolni za IŠRM
\vfill

\begin{center}
  \large
  \imeavtorja\\[3mm]
  \Large
  \textbf{\MakeUppercase{\naslovdela}}\\[10mm]
  \large
  Magistrsko delo \\[1cm]
  Mentor: \imementorja \\[2mm] % ustrezno popravi spol
%   Somentor: \imesomentorja   % dodaj, če potrebno
\end{center}
\vfill

\noindent{\large Ljubljana, \letnica}

\cleardoublepage

%% sem pride IZJAVA O AVTORSTVU  -- SE NATISNE V VIS

% zahvala
\pdfbookmark[1]{Zahvala}{zahvala} %
\section*{Zahvala}
Neobvezno.
Zahvaljujem se \dots
% end zahvala -- izbriši vse med zahvala in end zahvala, če je ne rabiš

\cleardoublepage

\pdfbookmark[1]{\contentsname}{kazalo-vsebine}
\tableofcontents

% list of figures
% \cleardoublepage
% \pdfbookmark[1]{\listfigurename}{kazalo-slik}
% \listoffigures
% end list of figures

\cleardoublepage

\section*{Program dela}
% \addcontentsline{toc}{section}{Program dela} % dodajmo v kazalo
% Mentor naj napiše program dela skupaj z osnovno literaturo. Na literaturo se
% lahko sklicuje kot~\cite{lebedev2009introduction}, \cite{gurtin1982introduction},
% \cite{zienkiewicz2000finite}, \cite{STtemplate}.

\section*{Osnovna literatura}
% Literatura mora biti tukaj posebej samostojno navedena (po pomembnosti) in ne
% le citirana. V tem razdelku literature ne oštevilčimo po svoje, ampak uporabljamo
% okolje itemize in ukaz plancite, saj je celotna literatura oštevilčena na koncu.
% \begin{itemize}
%   \plancite{lebedev2009introduction}
%   \plancite{gurtin1982introduction}
%   \plancite{zienkiewicz2000finite}
%   \plancite{STtemplate}
% \end{itemize}

\vspace{2cm}
\hspace*{\fill} Podpis mentorja: \phantom{prostor za podpis}

% \vspace{2cm}
% \hspace*{\fill} Podpis somentorja: \phantom{prostor za podpis}

\cleardoublepage
\pdfbookmark[1]{Povzetek}{abstract}

\begin{center}
\textbf{\naslovdela} \\[3mm]
\textsc{Povzetek} \\[2mm]
\end{center}
Tukaj napišemo povzetek vsebine. Sem sodi razlaga vsebine in ne opis tega, kako je delo
organizirano.

\vfill
\begin{center}
\textbf{English translation of the title} \\[3mm] % prevod slovenskega naslova dela
\textsc{Abstract}\\[2mm]
\end{center}

An abstract of the work is written here. This includes a short description of
the content and not the structure of your work.

\vfill\noindent
\textbf{Math.~Subj.~Class.~(2010):} oznake kot 74B05, 65N99, na voljo so na naslovu
\url{http://www.ams.org/msc/msc2010.html} \\[1mm]
\textbf{Ključne besede:} \kljucnebesede \\[1mm]
\textbf{Keywords:} \keywords

\cleardoublepage

\setcounter{page}{1}    % od sedaj naprej začni zopet z 1
\pagenumbering{arabic}  % in z arabskimi številkami


% ================================================================================================================================================================== %
% ================================================================================================================================================================== %
% NAVODILA / PRIMERI

% \section{Uvod}
% Napišite kratek zgodovinski in matematični uvod.  Pojasnite motivacijo za problem, kje
% nastopa, kje vse je bil obravnavan. Na koncu opišite tudi organizacijo dela -- kaj je v
% katerem razdelku.

% \section{Integrali po \texorpdfstring{$\omega$}{ω}-kompleksih}
% \subsection{Definicija}
% \begin{definicija}
%   Neskončno zaporedje kompleksnih števil, označeno z $\omega = (\omega_1, \omega_2, \ldots)$,
%   se imenuje \emph{$\omega$-kompleks}.\footnote{To ime je izmišljeno.}

%   Črni blok zgoraj je tam namenoma. Označuje, da \LaTeX{} ni znal vrstice prelomiti pravilno
%   in vas na to opozarja. Preoblikujte stavek ali mu pomagajte deliti problematično besedo z
%   ukazom \verb|\hyphenation{an-ti-ko-mu-ta-ti-ven}| v preambuli.
% \end{definicija}
% \begin{trditev}[Znano ime ali avtor]
%   \label{trd:obstoj-omega}
%   Obstaja vsaj en $\omega$-kompleks.
% \end{trditev}
% \begin{proof}
%   Naštejmo nekaj primerov:
%   \begin{align}
%     \omega &= (0, 0, 0, \dots), \label{eq:zero-kompleks} \\
%     \omega &= (1, i, -1, -i, 1, \ldots), \nonumber \\
%     \omega &= (0, 1, 2, 3, \ldots). \nonumber \qedhere  % postavi QED na zadnjo vrstico enačbe
%   \end{align}
% \end{proof}

% \section{Tehnični napotki za pisanje}

% \subsection{Sklicevanje in citiranje}
% Za sklice uporabljamo \verb|\ref|, za sklice na enačbe \verb|\eqref|, za citate \verb|\cite|. Pri
% sklicevanju in citiranju sklicano številko povežemo s prejšnjo besedo z nedeljivim presledkom
% $\sim$, kot npr.\ \verb|iz trditve~\ref{trd:obstoj-omega} vidimo|.

% \begin{primer}
%   Zaporedje~\eqref{eq:zero-kompleks} iz dokaza trditve~\ref{trd:obstoj-omega} na
%   strani~\pageref{trd:obstoj-omega} lahko najdemo tudi v Spletni enciklopediji zaporedij~\cite{oeis}.
%   Citiramo lahko tudi bolj natančno~\cite[trditev 2.1, str.\ 23]{lebedev2009introduction}.
% \end{primer}

% \subsection{Okrajšave}
% Pri uporabi okrajšav \LaTeX{} za piko vstavi predolg presledek, kot npr. tukaj. Zato se za vsako
% piko, ki ni konec stavka doda presledek običajne širine z ukazom \verb*|\ |, kot npr.\ tukaj.
% Primerjaj z okrajšavo zgoraj za razliko.

% \subsection{Vstavljanje slik}
% Sliko vstavimo v plavajočem okolju \texttt{figure}. Plavajoča okolja \emph{plavajo} po tekstu, in
% jih lahko postavimo na vrh strani z opcijskim parametrom `\texttt{t}', na lokacijo, kjer je v kodi s
% `\texttt{h}', in če to ne deluje, potem pa lahko rečete \LaTeX u, da ga \emph{res} želite tukaj,
% kjer ste napisali, s `\texttt{h!}'. Lepo je da so vstavljene slike vektorske (recimo \texttt{.pdf}
% ali \texttt{.eps} ali \texttt{.svg}) ali pa \texttt{.png} visoke resolucije (več kot
% \unit[300]{dpi}).  Pod vsako sliko je napis in na vsako sliko se skličemo v besedilu. Primer
% vektorske slike je na sliki~\ref{fig:sample}. Vektorsko sliko prepoznate tako, da močno
% zoomate v sliko, in še vedno ostane gladka. Več informacij je na voljo na
% \url{https://en.wikibooks.org/wiki/LaTeX/Floats,_Figures_and_Captions}. Če so slike bitne, kot na
% primer slika~\ref{fig:image}, poskrbite, da so v dovolj visoki resoluciji.

% \begin{figure}[h]
%   \centering
%   \includegraphics[width=0.6\textwidth]{images/sample.pdf}
% % \caption[caption za v kazalo]{Dolg caption pod sliko}
%   \caption[Primer vektorske slike.]{Primer vektorske slike z oznakami v enaki pisavi, kot jo
%      uporablja \LaTeX{}.  Narejena je s programom Inkscape, \LaTeX{} oznake so importane v
%      Inkscape iz pomožnega PDF.}
%   \label{fig:sample}
% \end{figure}

% \begin{figure}[h]
%   \centering
%   \includegraphics[width=0.8\textwidth]{images/image.png}
%   \caption[Primer bitne slike.]{Primer bitne slike, izvožene iz Matlaba. Poskrbite, da so slike v
%   dovolj visoki resoluciji in da ne vsebujejo prosojnih elementov (to zahteva PDF/A-1b format).}
%   \label{fig:image}
% \end{figure}


% ================================================================================================================================================================== %
% ================================================================================================================================================================== %


\section{Uvod}

% stvari za dat v uvod:
% motivacija/"the pitch"
% cilj naloge
% poudarek na "our stuff"
% pregled poglavji

% ===== THE PITCH ===== %

% === motivacija problema === %
% Neki neki - kaj je strojno učenje.
% Omemba, da je v strojnem učenju prekletstvo dimenzionalnosti pogost problem.
% Rešujemo ga z "manjšanjem razsežnosti".
% Standard pristop so samokodirniki.
Strojno učenje je področje umetne inteligence posvečeno preučevanju algoritmov, ki izboljšujejo svoje delovanje skozi čas.
Pogost izziv pri strojnem učenju je delo z množicami visokih razsežnosti, pri katerem pride do pojava imenovanega ``prekletstvo razsežnosti''.
Rešujemo ga z manjšanjem razsežnosti množic, ob tem pa želimo ohraniti čim večjo količino informacij.
Popularna metoda za manjšanje razsežnosti množic je uporaba samokodirnikov.

% === Kaj so samokodirniki in kako pomagajo? === %
% Samokodirniki pa standardno temeljijo na uporabi modela nevronskih mrež.
% Nevronske mreže imajo nekatere slabosti, ki se izrazijo tudi pri takih samokodirnikih.
% Želimo implementirati različico samokodirnika, ki bi se soočila z nekaterimi izmed teh slabosti.
Samokodirnik je model, ki podatkovno množico preslika v nek drug prostor, ki je praviloma manjše razsežnosti, nato pa jo ponovno preslika v prvotni prostor. % TODO: bolj formalno
Če je rekonstruirana množica dober približek prvotne množice, sklepamo, da vmesni prostor ohrani večino informacij v množici in lahko vmesno predstavitev množice uporabimo namesto prvotne. % razbit na dve povedi
Standardni samokodirniki so zgrajeni iz modela (usmerjene) nevronske mreže.
Nevronske mreže in posledično standardni samokodirniki imajo nekaj velikih slabosti: so časovno neučinkovite, iz vidika uporabnika so ``črna škatla'',...

% === cilj === %
% cilj dela je razvoj in implementacija bolj jasnega, itd. samokodirnika.
% Za ta namen je naključni gozd zelo primerna osnova - dobra natančnost, dobro razumevanje za uporabnika, itd.
% Želimo torej razviti samokodirnik na osnovi naključnega gozda.
% Njegovo delovanje želimo nato še preizkusiti v primerjavi s standardnimi samokodirniki in ga ovrednotiti.
V delu želimo konstruirati in implementirati samokodirnik, ki se bo soočil s slabostmi standardnega pristopa.
Izkaže se, da je model naključnega gozda dobra osnova, saj v splošnem dosega dobro natančnost, ima sorazmerno hiter postopek učenja in uporabniku omogoča bolj jasen vpogled v delovanje.
Zato smo se v delu odločili razviti samokodirnik na osnovi naključnega gozda.
Novo različico samokodirnika nato še testiramo in njeno delovanje ovrednotimo v primerjavi s standardnim pristopom.

% naše delo
% Model naključnega gozda že sam napoveduje rekonstruirane primere - želimo izkoristiti podatke iz njega in konstruirati samokodirnik.
% Glede na strukturo dreves v gozdu lahko zakodiramo primere - naberemo množico najbolj "pomembnih" listov in kodiramo glede na njih.
% Postopek kodiranja je preprost - glede na to, kam spadajo primeri.
% Postopek dekodiranja je bolj zahteven, želimo čim boljšo rekonstrukcijo.
% Izkoristimo napovedi dreves v gozdu in algoritem DPLL za reševanje SAT problema za rekonstrukcijo vrednosti.
Model naključnega gozda bomo naučili za napovedovanje vrednosti vhodnih spremenljivk, nato pa moramo model še predelati v samokodirnik.
Primeri, ki v odločitvenem drevesu iz gozda pripadajo istemu listu, so si v neki lastnosti podobni.
S pripadnostjo listom lahko torej opišemo primere in želimo izbrati kodirni vektor najpomembnejših listov iz gozda, ki bojo skupaj čim bolje opisali množico.
Primere iz podatkovne množice zakodiramo glede na to, katerim listom iz kodirnega vektorja pripadajo.
Pri postopku dekodiranja želimo čim bolj natančno rekonstruirati prvotno vrednost primerov in v ta namen uporabimo shranjene napovedi odločitvenih dreves ter prilagojen algoritem DPLL.

% ===== PREGLED POGLAVJI ===== %

% strojno učenje
% TODO: skrajšati, preveriti, da res vse omenimo.
V poglavju~\ref{pogl:strojno_ucenje} pregledamo osnove strojnega učenja in definiramo standardne pojme, ki jih uporabljamo v preostanku besedila. 
Najprej opišemo delitev na področji nadzorovanega in nenadzorovanega učenja.
Nato obravnavamo problematiko učenja iz podatkovnih množic visokih razsežnosti, 
kjer se med drugim pojavi problem t.~i.~``prekletstva razsežnosti'' (ang.~curse of dimensionality). 
Opišemo tudi glaven način soočanja s to problematiko - manjšanje razsežnosti (ang.~dimensionality reduction), ki se mu posvetimo v preostanku magistrske naloge.

% samokodirniki
% Opis samokodirnikov.
% Definicija usmerjenih nevronskih mrež.
% Opis standardnega samokodirnika.
V poglavju o samokodirnikih podrobno definiramo pojem samokodirnika ter način, kako ga vrednotimo.
Definiramo model usmerjene nevronske mreže, njegovo uporabo ter prednosti in slabosti.
Nato opišemo še standardne samokodirnike, ki so iz njih zgrajeni, in vrste samokodirnikov.

% samokodirnik zgrajen iz naključnega gozda
% Definiramo odl. drevo in nato naključni gozd.
% Razmislek, da določeni listi na nek način določajo primere?
% Konstrukcija kodirnika.
% Konstrukcija dekodirnika.
V četrtem(?) poglavju konstruiramo samokodirnik na osnovi naključnega gozda.
Najprej definiramo modela odločitvenega drevesa in naključnega gozda.
Nato vpeljemo pojme kodirnega vektorja, pripadnosti primera listu in mero kvalitete/podobnosti listov, da lahko konstruiramo kodirnik.
Pri konstrukciji dekodirnika predstavimo SAT problem in KNO formule. 
Utemeljimo, da je izziv pri dekodiranju predstavljen v obliki KNO formule in lahko zato pri reševanju uporabimo prirejen DPPL algoritem.
Na koncu razdelka še opišemo postopek dekodiranja s pomočjo shranjenih napovedi in prirejenega DPLL algoritma.

% implementacija
% Povemo, da delamo v pythonu in to/zakaj.
% Parametri.
% Komponente.
% Različice algoritmov in možne izboljšave.
Za implementacijo samokodirnika smo izbrali Python, pri obdelavi podatkov pa uporabimo tudi R.
V poglavju namenjenemu implementaciji opišemo knjižnice, ki smo jih uporabili, in najpomembnejše parametre samokodirnika.
Naštejemo komponente, na katere smo razdelili skripto, ter naštejemo, katere funkcije se nahajajo v kateri komponenti.
Nato opišemo še drugačne različice algoritma, ki smo jih implementirali, in možne izboljšave za naprej.

% <<<< YOU ARE HERE - TODO
% vrednotenje
TODO???


% ====================  STROJNO UČENJE ==================== %
\section{Strojno učenje}
\label{pogl:strojno_ucenje}

\subsection{Osnove}

% Uvod v poglavje, ki kratko opiše vsebino poglavja? ga sestavimo še enkrat krajše?
% LEFTOVER TEXT
% V tem poglavju bomo pregledali osnove strojnega učenja in definirali standardne pojme, ki jih bomo uporabljali v prihodnjih poglavjih. 
% Najprej bomo opisali delitev na področji nadzorovanega in nenadzorovanega učenja, 
% nato pa bomo obravnavali problematiko učenja iz podatkovnih množic visokih razsežnosti, 
% kjer se med drugim pojavi problem t.~i.~``prekletstva razsežnosti'' (ang.~curse of dimensionality). 
% Opisali bomo tudi glaven način soočanja s to problematiko - manjšanje razsežnosti (ang.~dimensionality reduction), ki se mu bomo posvetili v preostanku magistrske naloge.

% Kratek opis strojnega učenja in delitve na nadzorovano/nenadzorovano.
Strojno učenje je področje umetne inteligence posvečeno preučevanju algoritmov, 
ki izboljšujejo svoje delovanje skozi čas (TODO: sklic na Elements of Statistical Learning). 
Pogosto ga uporabljamo za avtomatizirano analizo podatkov, pri kateri algoritmi napovedujejo vrednosti izbranega podatkovnega elementa ali pa razpoznavajo skupine medsebojno podobnih podatkov. 
Strojno učenje uporabljamo v mnogih panogah in njegova popularnost hitro raste, ker se odkriva njegovo uporabnost pri vse več različnih problemih. 
Metode strojnega učenja, ki se ukvarjajo z algoritmi za napovedovanje imenujemo tudi metode za nadzorovano učenje (ang.~supervised learning). 
Z uporabo zabeleženih vrednosti podatkovnega elementa, ki ga napovedujemo, lahko namreč ``nadzorujemo'' njihovo delovanje. 
Metode, kjer takega nadzora ni, pa uvrščamo na področje nenadzorovanega učenja (ang.~unsupervised learning). 
V tem primeru je cilj metod najti vzorce v podatkih, npr.\ razpoznati množice medsebojno podobnih podatkovnih primerov ali pa kombinacije podobnih podatkovnih elementov, ki se pogosto ponavljajo.

% primeri nadzorovanega in nenadzorovanega učenja
Znani primeri uporabe nadzorovanega učenja so napovedovanje vrednosti delnic, prepoznavanje malignih tvorb v medicini, tj.~napovedovanje ali je tvorba maligna, priporočanje nove vsebine in oglasov uporabnikom spleta,... 
Primeri uporabe nenadzorovanega učenja pa so npr.\ razpoznavanje skupin podobnih uporabnikov na družbenem omrežju, prepoznavanje trendov v finančnem portfelju, prepoznavanje skupin podobnih artiklov v spletni trgovini ali podobnih skladb na strani za glasbo,\dots

% ==================== %

\subsubsection{Nadzorovano učenje}

% Kratek opis in primeri uporabe nadzorovanega učenja. Vključimo postopek in cilj učenja.
Nadzorovano učenje je veja strojnega učenja, ki se ukvarja z razvojem algoritmov za napovedovanje izbranega podatkovnega elementa. 
Algoritem za napovedovanje podatkovnega elementa imenujemo \emph{model} in želimo, da je čim bolj točen. 
Podatke za obdelavo mora ponavadi pregledati človek, da določi element podatkov, ki ga bo model napovedoval.
To, da je element podatkov za napovedovanje vnaprej določen, pa omogoči vrednotenje natančnosti modela, saj lahko na izmerjenih primerih napoved primerjamo z dejansko vrednostjo. 
Model nato popravimo tako, da njegove napovedi postanejo bolj točne, in na tak način nadzorujemo njegovo učenje. 
Nadzorovano učenje je zelo popularno in se uporablja v mnogih različnih panogah. Primeri uporabe so 
npr.\ ocenjevanje tveganja v financah, kjer model napove tveganje poslovnega podviga ali pa plačilno sposobnost osebe, 
priporočanje spletnemu uporabniku prilagojene vsebine in oglasov, napovedovanje vremenskih pojavov, prepoznavanje malignih tvorb pri pacientih v zdravstvu,...

\begin{definicija}
Denimo, da je v množici podatkov spremenljivka $Y$ element podatkov, ki je izbran za napovedovanje, in ima zalogo vrednosti $D_Y$. 
Poleg tega pa množica podatkov vsebuje še $p$ spremenljivk $X_1, \ldots , X_p$ ter je za $i = 1, \ldots, p$ z $D_i$ označena zaloga vrednosti spremenljivke $X_i$. 
V tem primeru je sledeč skalarni produkt množica možnih primerov, ki jo bomo označevali z $\omega$:
$$
\omega = D_1 \times D_2 \times \dots \times D_p \times D_Y.
$$

\textbf{Podatkovna množica}, ki jo uporabimo za strojno učenje, je množica $S \subseteq \omega$. 
Posamezen primer, ki ga obravnava algoritem strojnega učenja, pa je vektor oblike $(x_1, x_2, \ldots , x_p, y) \in S$. 
Definirajmo še nekaj drugih osnovnih izrazov, ki jih uporabljamo v strojnem učenju.

Spremenljivko $Y$, ki jo model napoveduje, imenujemo \textbf{ciljna spremenljivka} oz.~izhodna spremenljivka. 
Ostale spremenljivke, tj.~$X_1, \ldots , X_p$ imenujemo \textbf{napovedne spremenljivke} oz.~vhodne spremenljivke. 
\textbf{Razsežnost} podatkovne množice za učenje pa je število napovednih spremenljivk, v tem primeru torej $p$.
\end{definicija}

V množici podatkov za obdelavo je torej vnaprej izbrana ciljna spremenljivka. 
Množica podatkov pa vsebuje vektorje, kjer je ena spremenljivka izhodna, ostale pa vhodne. 
Pomembno se je zavedati, da ciljna spremenljivka ni nujno skalar. 
Podatkovni element, ki ga želimo napovedovati lahko vsebuje več spremenljivk. 
V tem primeru bi lahko govorili o več ciljnih spremenljivkah, vendar bomo raje privzeli, da je ciljna spremenljivka zgolj ena. 
Ta spremenljivka pa je lahko večdimenzionalna in v tem primeru je njena vrednost predstavljena z vektorjem.

% TODO: prebrat diplomo od Sare za primerjat popravljene definicije

% delitev na diskretno in numerično
Omenimo še, da spremenljivke delimo na dve vrsti, kar je najbolj pomembno pri ciljni spremenljivki. Če je $Y$ \emph{numerične spremenljivka}, ima zalogo vrednosti $D_Y \subseteq \mathbb{R}$ in so njene vrednosti lahko racionalna števila. Če pa je $Y$ \emph{diskretna spremenljivka}, je njena zaloga vrednosti neka diskretna množica. To je lahko podmnožica naravnih števil, množica barv, ali pa množica različnih besed. Take množice lahko predstavimo s podmnožico naravnih števil, vendar se moramo zavedati, da to lahko ustvari med primeri ''bližino'', ki v prvotni množici ni prisotna. Zaradi tega diskretne spremenljivke ponavadi obravnavamo z drugačnimi metodami kot numerične.

% nekaj povemo o tem, da predpostavljamo, da so podatki v prostoru nekako porazdeljeni in želimo s pomočjo modela to porazdelitev čim bolje ocenit. 
Predpostavimo, da so primeri v podatkovni množici $S$ porazdeljeni po neki porazdelitvi. Želimo, da model to porazdelitev čim bolje aproksimira na sledeč način. Modelu podamo vektor vrednosti napovednih spremenljivk, vrne pa oceno vrednosti ciljne spremenljivke, ki želimo, da se čim bolje ujema s prvotno porazdelitvijo. Opisali smo že, kaj je model, zapišimo pa še formalno definicijo.

% Definicija modela strojnega učenja. % def
\begin{definicija}
\textbf{Model} $m$ je funkcija, ki slika iz množice $D_1 \times \ldots \times D_p$ v množico $D_Y$:
$$
m: \prod_{i=1}^p D_i \rightarrow D_Y.
$$
\end{definicija}

% Povemo, da želimo način vrednotenja modelov, da bomo lahko iskali čim boljše.
Naj bo vektor $(x_1, \ldots, x_p, y) \in S$ vzorec vrednosti, ki smo jih izmerili iz opazovane porazdelitve. Model $m$ vektorju izmerjenih vrednosti napovednih spremenljivk $x=(x_1, \ldots, x_p)$ priredi oceno vrednosti ciljne spremenljivke $\hat{y}=m(x)$. Seveda želimo, da je ocena vrednosti ciljne spremenljivke čim bližje dejanski vrednosti $y$, pri tem pa se pojavi vprašanje, kako definirati razliko med oceno in izmerjeno vrednostjo.

\begin{definicija}
\textbf{Funkcija izgube} $L: D_Y \times D_Y \rightarrow \mathbb{R}_+$ je taka preslikava, da za poljuben element $y \in D_Y$ velja $L(y,y) = 0$.
\end{definicija}

Razliko med oceno $\hat{y}$ in izmerjeno vrednostjo spremenljivke opišemo z vrednostjo funkcije izgube pri argumentih $\hat{y}$ in $y$. Omenili smo, da spremenljivke delimo na numerične in diskretne in glede na vrsto spremenljivke moramo uporabiti primerno funkcijo izgube. Poglejmo si primer dveh različnih funkcij izgube.

%  primer funkcije izgube za diskretno in numerično
\begin{primer}
Najprej obravnavajmo primer, ko je ciljna spremenljivka numerična. Denimo, da je zaloga vrednosti ciljne spremenljivke $D_Y = [-1,1]$. Naj velja $u, v \in  D_Y$. V tem primeru lahko uporabimo kvadratno funkcijo izgube (ang.~square loss function), ki je definirana s sledečim predpisom:
$$
L(u,v) = (u - v)^2.
$$

V primeru, ko je ciljna spremenljivka diskretna pa moramo uporabiti drugačno funkcijo izgube, saj razlika med dvema elementoma pogosto ni definirana. 
Denimo, da je $Y$ diskretna ciljna spremenljivka z zalogo vrednosti $D_Y = \{a,b,c,d,e\}$. 
Naj bosta $u$ in $v$ elementa $D_Y$. Za tako ciljno spremenljivko lahko uporabimo funkcijo izgube s sledečim predpisom:
\[
L(u,v) =
\begin{cases}
1 &;\ u= v \\
0 &; \text{ sicer}\ \ .
\end{cases}
\]
Vrednost funkcije izgube je $1$, če sta argumenta enaka, sicer pa je $0$. S tem imamo funkcijo izgube, ki upošteva zgolj to, ali sta dva elementa enaka, in ne uporablja razlike med elementi, ki jih ne moremo primerjati.
\end{primer}

Vemo torej, da vrednost $L(\hat{y}, y)$ predstavlja napako napovedi modela, vendar modela ne želimo vrednotiti zgolj glede na točnost napovedi pri enem primeru. Da bi model lahko bolje vrednotili, bomo združili vrednosti funkcije izgube pri več različnih primerih.

\begin{definicija}
\label{def-funkcija-napake}
Naj bo $L: D_Y \times D_Y \rightarrow \mathbb{R}_+$ funkcija izgube in $m: \prod_{i=1}^p D_i \rightarrow D_Y$ model. Potem \textbf{funkcijo napake} $Err: (\prod_{i=1}^p D_i \rightarrow D_Y) \times \mathcal P (\omega) \rightarrow \mathbb{R}_+$ definiramo s predpisom:
\[
Err(m,S) = \frac{1}{|S|} \sum_{(x,y) \in S} L(m(x),y).
\]
\end{definicija}

% razlaga definicije
Funkcija izgube kot argumenta prejme model $m$ in množico podatkov $S \subseteq \omega$. Argumentoma priredi vsoto vrednosti funkcije izgube za model $m$ pri vseh primerih množice $S$, deljeno s številom primerov v množici $S$. Vrednost funkcije izgube pri teh argumentih, ki ji pravimo tudi izguba modela $m$ na množici $S$, je torej povprečna vrednost funkcije izgube za model $m$ na množici $S$.

% Uporabimo funkcijo napake pri algoritmu, ki išče model s čim manjšo napako.
Definirali smo, kako vrednotimo točnost modela, želimo pa najti še postopek, s katerim bi lahko poiskali čim boljši model. Predpostavimo, da imamo podano množico podatkov, ki jo želimo uporabiti, da zgradimo model, ki bo čim bolje napovedoval vrednosti porazdelitve, s katero so bili podatki generirani.

% Definiramo metodo strojnega učenja, tj. postopek učenja.
\begin{definicija}
Naj bodo množice $D_1, D_2, \ldots, D_p$ zaloge vrednosti napovednih spremenljivk in množica $D_Y$ zaloga vrednosti ciljne spremenljivke. 
\textbf{Metoda strojnega učenja} $A$ je preslikava sledeče oblike:
\[
A: \mathcal{P}(\prod_{i=1}^p D_i \times D_Y) \rightarrow (\prod_{i=1}^p D_i \rightarrow D_Y).
\]
\end{definicija}

% Razlaga definicije
Metoda strojnega učenja je torej preslikava, ki množici podatkov priredi nek model. Želimo pa seveda, da bi ta model bil čim bolj točen - dosegal čim manjšo vrednost funkcije napake. Ponavadi za izgradnjo takšnega modela uporabimo kakšen standardni optimizacijski algoritem. (TODO: sklic na vir o kakšni standardni metodi učenja, npr.\ gradient descent)

% Želimo model, ki je splošno točen, zato množico podatkov ločimo na testno in učno, da lahko rezultate dobro ocenimo.
Predpostavimo, da imamo neko množico podatkov in želimo zgraditi model za napovedovanje porazdelitve, s katero so bili podatki generirani. 
Lahko bi celo množico uporabili, da z metodo strojnega učenja zgradimo primeren model. 
Vendar lahko v tem primeru naletimo na težavo, da ima model na novih izmerjenih primerih iz iste porazdelitve precej večjo napako. 
To se zgodi v primeru, ko je model učni množici pretirano prilagojen in je zaradi tega na ostalih primerih manj natančen. 
Mi pa želimo, da bi model bil splošno veljaven in bi čim boljšo natančnost dosegal tudi na novih primerih. 
Zaradi tega množico primerov razdelimo na dva dela - na učno množico in na testno množico. 
Učno množico se uporabi za izgradnjo modela, na testni množici pa lahko preverimo napako modela na podatkih, ki niso bili uporabljeni pri izgradnji. 
S tem dobimo perspektivo, če se napovedi modela dobro posplošijo na nove primere ali pa je model morda preveč prilagojen učni množici.

% TODO: sklic na to, da ne obstaja model, ki bi bil univerzalno najboljši?

% ==================== %

\subsubsection{Nenadzorovano učenje}

% Kratek opis in primeri uporabe nenadzorovanega strojnega učenja.
% TODO: preverit kako je oblikovan tekst o podatkovni množici
Nenadzorovano učenje je druga veja strojnega učenja, od nadzorovanega pa se razlikuje predvsem v tem, da problemi nenadzorovanega učenja nimajo ciljne spremenljivke. 
Množica možnih primerov pri nenadzorovanem učenju je torej $\omega = D_1 \times \cdots \times D_p$, kjer za $i= 1,\ldots, p$ velja, da je $D_i$ zaloga vrednosti spremenljivke $X_i$. 
Podatkovna množica pri problemih nenadzorovanega učenja je $S \subseteq \omega$ in v tem primeru je razsežnosti $p$. 
Cilj nenadzorovanega učenja je z algoritmom pridobiti vpogled v množico podatkov in zaradi bolj odprte narave zastavljene naloge ni potreben človeški pregled množice za obdelavo. 
Zanimajo nas lahko na primer vzorci v množici, korelacija med primeri, osamelci, itd.

% primeri
Pogosta primera sta analiza glavnih komponent (ang.~principal component analysis, krajše PCA), ki poišče glavne značilnosti množice, 
in razvrščanje v skupine (ang.~clustering), kjer se množico razdeli na podmnožice med seboj najbolj podobnih primerov. 
Nenadzorovano učenje se med drugim uporablja za prepoznavanje podobnih skupin uporabnikov na spletu (npr.\ v namen oglaševanja), 
za ocenjevanje glavnih lastnosti finančnega portfelja, za grupiranje spletne vsebine v med seboj podobne skupine, s čimer se lahko uporabniku predlaga povezane artikle,...

% Formalno definiramo problem nenadzorovanega učenja - z navezovanjem na nadzorovano učenje, torej da ni ciljne spremenljivke.
Pod nenadzorovano učenje spada mnogo pristopov in algoritmov, ki obdelajo množico podatkov in vrnejo rezultat v veliko različnih možnih oblikah. Skupna definicija, ki bi opisala vse te postopke, bi bila okorna in preveč splošna, da bi bila uporabna. Namesto, da bi uvedli splošno definicijo, si bomo podrobno ogledali en primer algoritma, s pomočjo katerega bomo spoznali pristop nenadzorovanega učenja.
% Primer učne množice

\begin{primer}
% NOTE: bolj podroben opis algoritma je v elements of statistical learning
Naj bo $S \subseteq \omega$ podatkovna množica, ki ima razsežnost $p$. 
Opisali bomo osnoven postopek razvrščanja $k$-voditeljev (ang.~$k$-means clustering). 
Cilj algoritma je elemente množice razvrstiti v $k$ skupin med seboj podobnih elementov.

% TODO: image???

Postopek se začne tako, da v prostoru naključno izberemo $k$ točk $\mu_1, \mu_2, \ldots , \mu_k$. 
Nato za vsako točko $x \in S$ izračunamo, kateri $\mu_i$ leži najbližje. Če $x$ leži najbližje točki $\mu_i$, pravimo, da pripada $i$-ti skupini. 
Po tem, ko so vse točke razvrščene v skupine, izračunamo nove vrednosti $\mu_1, \ldots , \mu_k$ tako, da za $i=1,\ldots,k$ določimo $\mu_i$ kot povprečje vseh elementov $i$-te skupine. 
Ta postopek nadaljujemo dokler rezultat ne konvergira. TODO: opomba, da morajo točke biti vstavljene v evklidski prostor (da lahko izračunamo povprečje)

S tem je množica $S$ razdeljena na $k$ skupin med seboj podobnih primerov. 
Slabost takega pristopa pa je, da je lahko preveč preprost in ne zajame veliko nians podatkovne množice. 
Glede na različne začetne parametre je možno primere razdeliti na več različnih, veljavnih, skupin primerov. 
Posamezna delitev je lahko pravilna, vendar morda iz podatkovne množice ne prepozna tistih podobnosti, ki smo jih želeli.
\end{primer}

% Odstavek o tem, da ta naloga povezuje oboje? mogoče raje kasneje v tekstu

% Povezava v naslednje poglavje: v delu bomo obravnavali obe vrsti učenja, pri obeh vrstah strojnega učenja pa pogosto obravnavamo množice velikih razsežnosti...
Ogledali smo si primer nenadzorovanega učenja, zapomniti pa si moramo, da obstaja še precej drugih postopkov in algoritmov, ki spadajo v to vejo strojnega učenja. 
Med drugim se metode nenadzorovanega učenja uporabljajo tudi pri manjšanju razsežnosti množic. 
To je pogost izziv strojnega učenja, saj se pri množicah visokih razsežnosti pojavijo ovire, ki otežujejo obdelavo. 
Najpogostejši način soočanja s temi ovirami je manjšanje razsežnosti množice, ki ga bomo opisali v naslednjem poglavju.


% ========================= %

\subsection{Učenje iz množic visoke razsežnosti}

% Motivacija za obravnavo visoko dimenzionalnih množic. Razlaga, da je to pogost problem, in kratek povzetek razdelka.
Pri večini problemov, za katere se v praksi uporablja strojno učenje, se srečamo z množicami visokih razsežnosti. 
Pri množicah podatkov iz področij financ, medicine, satelitskih posnetkov, in mnogih drugih, je število spremenljivk lahko zelo veliko. 
To pri obdelavi povzroča težave, množice pa pogosto vsebujejo tudi veliko število primerov, kar nekatere probleme obdelave še poveča. % skip?
V tem razdelku bomo podrobno opisali izzive, ki jih srečamo pri množicah visoke razsežnosti. 
Še posebej se bomo posvetili t.~i.~\emph{prekletstvu razsežnosti}, nato pa bomo predstavili še nekaj standardnih pristopov za manjšanje razsežnosti množic.

% Uvod v problematiko visokih dimenzij: potrebnega veliko procesorskega časa, itd. pride pa tudi do pojava ''prekletstva dimenzionalnosti'' - napeljemo uvod v naslednji razdelek.
Množice visokih razsežnosti pri obdelavi potrebujejo veliko pomnilnika in ogromno procesorskega časa. 
Zaradi tega je že zaradi omejenih računalniških zmogljivosti pogosto potrebno zmanjševanje razsežnosti. 
Izkaže pa se, da imajo take množice nekatere lastnosti, zaradi katerih je obdelava še posebej težavna, 
npr.\ da so elementi množice z večanjem razsežnosti med seboj vse bolj oddaljeni. 
Te lastnosti s skupnim imenom imenujemo prekletstvo razsežnosti in jih bomo podrobno predstavili v naslednjem razdelku.

% primer, ki ilustrira, koliko procesorskega časa potrebujemo?

% ==================== %

\subsubsection{Prekletstvo razsežnosti}

% Kratek opis težav, ki nastopijo pri prekletstvu dimenzionalnosti.
Videli bomo, da se pri večanju razsežnosti prostora na nek način spremeni položaj elementov v prostoru. 
Izkaže se, da so ob večanju razsežnosti primeri vse bolj zbrani ob robu prostora, saj se njihova razdalja do koordinatnega izhodišča veča. 
Prav tako se veča tudi povprečna razdalja med elementi. Obe lastnosti bomo v tem razdelku dokazali. 
S tem, da se razdalje med elementi večajo, potrebujemo tudi vse večje število primerov, če želimo ohraniti enako gosto porazdelitev primerov. 
Število potrebnih primerov za ohranjanje enako goste porazdelitve se veča eksponentno, kar v praksi pomeni, da pri bolj zahtevnih problemih ne moremo ohraniti enako gostega vzorca primerov. 
To obnašanje označimo s skupnim imenom prekletstvo razsežnosti.

V trditvi bomo predpostavke o prostoru nekoliko poenostavili, da bo izpeljava bolj elegantna. 
Prostor možnih primerov z $d$ dimenzijami je pri strojnem učenju ponavadi oblike $[-1, 1]^d$, ker se spremenljivke normira za lažjo obdelavo. 
Mi pa se bomo omejili na primere znotraj $d$ dimenzionalne enotske krogle. 
Ta primer bo za naš namen zadoščal, saj bo obnašanje primerov znotraj krogle nakazalo obnašanje primerov v celem prostoru.

% TODO: premisliti formulacijo. Je treba kej napisati bolj rigorozno?
\begin{trditev}
V enotski krogli v prostoru $\mathbb{R}^p$ enakomerno naključno izberemo $n$ točk. Mediana oddaljenosti točke, ki je koordinatnemu izhodišču najbližja, od izhodišča je:
\[
d(p, n)  = (1 - \frac{1}{2^{\frac{1}{n}}})^{\frac{1}{p}}.
\]
\end{trditev}

% Razlaga trditve, kjer se navežemo na že omenjene probleme in pojasnimo, kako jih trditev utemelji.
Vidimo, da se z večanjem števila točk $n$ mediana oddaljenosti najbližje točke manjša, z večanjem dimenzije $p$ pa narašča proti $1$. 
Torej bo v prostoru dovolj visoke razsežnosti izmed nabora $n$ izbranih točk še točka, ki je izhodišču najbližje, ponavadi bližje robu prostora kot izhodišču. 
Tudi če izberemo veliko število točk, bo to veljalo, če bo le razsežnost prostora dovolj velika.

% === DOKAZ === %
\begin{proof}

Volumen krogle s polmerom $r$ v prostoru $\mathbb{R}^p$ je: % TODO: citat
$$
r^p \frac{\pi^{\frac{p}{2}}}{\Gamma (\frac{p}{2}+1)},
$$
kjer $\Gamma$ označuje gama funkcijo (TODO: referenca? ali definicija Gamma funkcije). 
Naj bo $D$ slučajna spremenljivka, 
ki označuje razdaljo med koordinatnim izhodiščem in enakomerno naključno izbrano točko v enotski krogli. 
Naj bo $x \in (0,1)$ neko pozitivno število. 

Zanima nas verjetnost, da je enakomerno naključno izbrana točka od izhodišča oddaljena manj kot $x$, oz.~da velja $D \leq x$. 
Verjetnost, da to velja, pa je enaka razmerju med volumnom krogle s polmerom $x$ in volumnom enotske krogle. 
Vstavimo primerna polmera, tj.~$x$ in $1$, v zgoraj napisano formulo za volumen krogle in zapišimo kumulativno porazdelitveno funkcijo tega dogodka. 
Skrajšan zapis kumulativne porazdelitvene funkcije nato odvajamo, da dobimo gostoto porazdelitve.
% TODO: kje je v resnici smiselno pisat meje spremenljivke?
\begin{align}
F_D(x) & = P(D \leq x) = \frac{x^p \frac{\pi^{\frac{p}{2}}}{\Gamma (\frac{p}{2}+1)}}{1^p \frac{\pi^{\frac{p}{2}}}{\Gamma (\frac{p}{2}+1)}} = \frac{x^p}{1} = x^p,\  0 \leq x \leq 1 \\
f_D(x) & = P(D = x) = F_D '(x) = p x^{p-1},\  0 \leq x \leq 1
\end{align}

% TODO: izvrednotenje -> ??? boljši izraz ???
Slučajno spremenljivko $D$ ovrednotimo $n$-krat in opazujemo minimum dobljenih vrednosti. 
Tako dobljeni minimum je prav tako slučajna spremenljivka, ki jo označimo z $M$. 
Vrednost, ki jo dobimo z ovrednotenjem $M$, je enaka vrednosti, 
ki bi jo dobili, če bi enakomerno naključno izbrali $n$ točk in opazovali razdaljo od izhodišča do najbližje točke. 
Gostoto porazdelitve tako definirane slučajne spremenljivke opiše formula: (TODO: citat) %TODO: razlaga faktorjev? al bi bil samo citat dovolj???
\begin{align*}
f_M(y) & = n(1 - F_D(y))^{n-1} f_D(y) \\
f_M(y) & = n(1 - y^p)^{n-1} p y^{p-1}.
\end{align*}

Gostoto porazdelitve $f_M$ nato integriramo na intervalu $(-\infty,x]$, da dobimo kumulativno porazdelitveno funkcijo. 
Opazimo, da je gostota porazdelitve pri negativnih argumentih enaka $0$. 
To je smiselno, saj slučajna spremenljivka $M$ opisuje razdaljo in ni možno, da bi bila njena vrednost negativna. 
Interval integracije lahko torej skrčimo na nenegativne vrednosti, oz.~na interval $[0,x]$.
\begin{align*}
F_M(x) & = \int_{-\infty}^x n(1 - y^p)^{n-1} p y^{p-1} dy \\
& = \int_0^x n(1 - y^p)^{n-1} p y^{p-1} dy \\
& = \int_0^{x^p} n(1-z)^{n-1} dz \\
& = -(1 - z)^n \Big|_0^{x^p} \\
& = 1 - (1 - x^p)^n
\end{align*}

% TODO: stavek razlage katero zamenjavo uporabimo/izvedemo pri F_M izračunu
Za vrednost v trditvi nas zanima mediana oddaljenosti izhodišča do najbližje naključno izbrane točke. 
To pa je natanko mediana vrednosti slučajne spremenljivke $M$. 
Mediana je tisti argument, pri katerem bo polovica vrednosti večjih, polovica pa manjših. 
Pri dovolj velikem številu primerov bo mediana dosežena pri argumentu $x_0$ za katerega velja $F_M(x_0) = \frac{1}{2}$. 
V to zvezo vstavimo predpis kumulativne porazdelitvene funkcije in poračunamo vrednost argumenta.
\begin{align*}
1 - (1 - x_0^p)^n & = \frac{1}{2} \\
(1 - x_0^p)^n & = \frac{1}{2} \\
1 - x_0^p & = \frac{1}{2^{\frac{1}{n}}} \\
x_0 & = (1 - \frac{1}{2^{\frac{1}{n}}})^{\frac{1}{p}}
\end{align*}

Dokazali smo, da je vrednost mediane oddaljenosti, oz.~mediane vrednosti slučajne spremenljivke $M$, res enaka $(1 - \frac{1}{2^{\frac{1}{n}}})^{\frac{1}{p}}$.

\end{proof}

% komentar + posplošitev dokaza
Pokazali smo torej, da so primeri res vse bolj zbrani ob robu prostora, ko se veča razsežnost prostora. 
Opazimo, da bi lahko v dokazu namesto koordinatnega izhodišča izbrali poljubno drugo točko. 
Če bi izbrali neko točko v enotski krogli in obravnavali oddaljenost od te točke, bi lahko z analognim razmislekom pokazali podobno lastnost.

Denimo, da izmed množice $n$ naključnih točk najprej izberemo eno, ki jo bomo označili z $x_1$. 
Nato pa nas zanima, koliko bodo od $x_1$ oddaljene ostale točke. 
Naj bo $D'$ slučajna spremenljivka, ki označuje razdaljo med $x_1$ in enakomerno naključno izbrano točko v enotski krogli. 
Vrednost $D'$ je manjša ali enaka nekemu pozitivnemu $r$ natanko tedaj, ko se naključno izbrana točka nahaja v krogli s središčem $x_1$ in polmerom $r$. 
Če je ta krogla v  celoti vsebovana v enotski krogli, potem verjetnost dogodka $D' \leq r$ enako kot v dokazu opiše razmerje volumna dveh krogel. 

Lahko pa se zgodi, da del krogle ni vsebovan v enotski krogli. 
V tem primeru, je del prostora, v katerem mora ležati naključno izbrana točka, da velja $D' \leq r$, manjši. 
S tem se števec v ulomku zmanjša in se celotna verjetnost zmanjša - lahko pa jo navzgor omejimo z razmerjem, ki je bilo uporabljeno v dokazu. 
Ugotovili smo, da za poljuben argument $x$ iz enotske krogle velja $F_{D'}(x) \leq F_D(x)$. To mejo uporabimo in nato sledimo enakemu postopku kot prej.

Vidimo, da je mediana oddaljenosti najbližje točke večja ali enaka $(1 - \frac{1}{2^{\frac{1}{n-1}}})^{\frac{1}{p}}$, kar pomeni, 
da se razdalja od $x_1$ do najbližje točke veča z razsežnostjo. 
Podoben razmislek pa velja za poljubno točko v množici, torej se razdalja med vsemi točkami iz nabora izbranih točk z razsežnostjo povečuje.

\begin{primer}
Ogledali si bomo vrednosti mediane iz trditve pri dveh različnih fiksnih vrednostih $n$, da opazujemo, kako se razdalja spreminja glede na razsežnost prostora. Najprej fiksiramo vrednost $n=500$ in si ogledamo graf mediane oddaljenosti do izhodišča v odvisnosti od razsežnosti.

\begin{center}
\includegraphics[width=0.5\textwidth]{graf_oddaljenosti_500}
\end{center}

Vidimo, da vrednost preseže $0,5$ pri razsežnosti $p=10$, saj za mediano razdalje med izhodiščem in najbližjo naključno izbrano točko v tem primeru velja:
\[
d(10,500) \approx 0,5178.
\]

Torej je tudi najbližja točka verjetno bližje robu prostora kot izhodišču. 
Kot smo povedali v razmisleku pred primerom, se analogno povečuje tudi razdalja med točkami. 
Poglejmo si še primer s številom naključno izbranih točk $n=50000$. Opazimo, da vrednost mediane preseže $0,5$ pri razsežnosti $p=17$, kjer velja:
\[
d(17,50000) \approx 0,5179.
\]
Vidimo, da pri velikem povečanju števila izbranih točk vseeno zadošča sorazmerno majhno povečanje razsežnosti, da se vse točke spet zberejo bližje robu prostora. 
Podobno pa se z večanjem razsežnosti zelo hitro veča tudi razdalja med izbranimi točkami.

\begin{center}
\includegraphics[width=0.5\textwidth]{graf_oddaljenosti_50000}
\end{center}

% TODO: preuredit oznake/naslova grafov
\end{primer}

S to težavo se soočamo tako, da manjšamo število dimenzij ob čim manjši izgubi informacij.

% ==================== %

\subsubsection{Manjšanje razsežnosti množic}

% Uvod v ''dimensionality reduction'' kot način spopadanja s težavo visoko dimenzionalnih prostorov.
Zaradi težav z množicami visokih razsežnosti, ki smo jih opisali v razdelku $2.2$, uporabljamo metode za manjšanje razsežnosti množic, da bi učenje izboljšali. 
Pri večini metod za manjšanje razsežnosti domnevamo, da se množica podatkov v prostoru visoke razsežnosti nahaja na, 
oz.~blizu neke mnogoterosti manjše razsežnosti, ki je vsebovana v prostoru. Elemente množice podatkov nato obravnavamo v tem podprostoru manjše razsežnosti.
% TODO: preverit definicijo mnogoterosti
% TODO: prevod za embedding

% Nekaj o standardnih pristopih.
Obstaja veliko različnih pristopov za linearno manjšanje razsežnosti, pri katerih se množico podatkov z linearno preslikavo preslika v manj razsežen prostor. 
Pri tem želimo, da je predstavitev v manjši razsežnosti glede na neko merilo optimalna, npr.\ da dosega najmanjšo rekonstrukcijsko napako ali da ima preslikana množica čim večjo varianco. 
Znane metode za linearno manjšanje razsežnosti so npr.\ analiza glavnih komponent (ang.~principal component analysis, krajše PCA), 
analiza kanonične korelacije (ang.~ canonical correlations analysis, krajše CCA), linearna regresija, analiza faktorjev (ang.~factor analysis),... 
Število različnih pristopov za linearno manjšanje dimenzij je zelo veliko, saj so se neodvisno razvile na več različnih področjih, npr.\ v statistiki, strojnem učenju, itd. 
Obstajajo pa tudi raziskave, ki stremijo k združitvi in posplošitvi različnih metod linearnega manjšanja razsežnosti. Pregled in primerjavo različnih pristopov lahko bralec najde v (TODO: citat na Linear Dimensionality Reduction: Survey, Insights, and Generalizations)

% TODO: na hitro o nelinearnih pristopih
% komentar o tem, da se pogosto uporablja nenadzorovane metode. Samokodirniki so pa nadzorovana metoda?
Obstajajo tudi metode za nelinearno manjšanje razsežnosti, ki so pogosto nadgradnja nekaterih metod za linearno manjšanje razsežnosti. 
Omogočajo bolj kompleksno preslikavo v množico manjše razsežnosti, nekatere izmed teh metod pa so npr.\ Sammonova projekcija, jedrska analiza glavnih komponent (ang.~kernel principal component analysis, krajše: kernel PCA), samokodirniki,...
% TODO: Zaključek, da so dobra možna rešitev samokodirniki, ki se jim posvetimo v preostanku dela.
Samokodirniki so ena izmed najbolj razširjenih in uspešnih metod za manjšanje razsežnosti. 
V preostanku dela se ne bomo poglabljali v ostale metode, saj se bomo osredotočili na samokodirnike.


% ====================  SAMOKODIRNIKI ==================== %

% TODO: dodati angleške prevode ob prvi omembi pojmov
% TODO: upoštevat popravke!!!

\section{Samokodirniki}

% TODO: branje literature
Samokodirniki so ena izmed najbolj razširjenih in zmogljivih metod za manjšanje razsežnosti podatkovnih množic (TODO: citat, morda: A practical tutorial on autoencoders for nonlinear feature fusion). 
V tem poglavju bomo formalno definirali pojem samokodirnika in predstavili standardne samokodirnike, ki so sestavljeni iz usmerjenih nevronskih mrež. 
Zato bomo tudi formalno definirali model usmerjene nevronske mreže in opisali prednosti in slabosti njihove uporabe.
Pregledali bomo še najpogostejše vrste samokodirnikov in v katerem primeru jih je dobro uporabiti.
Večina samokodirnikov deli slabosti, ki jih imajo nevronske mreže, npr. počasen postopek učenja in slab vpogled v delovanje - iz vidika uporabnika so namreč ``črna škatla''.
Zato bomo v naslednjem poglavju nadaljevali s konstrukcijo drugačnega samokodirnika, ki bi to izboljšal.

% ostanek starega teksta
% Preden lahko podrobno razložimo standardno strukturo samokodirnika bomo zato morali definirati tudi model nevronske mreže. 
% Pregledali bomo najpogostejše vrste samokodirnikov, njihove prednosti in slabosti. 
% Pri uporabi nevronskih mrež so slabosti predvsem veliko porabljenega procesorskega časa in nejasnost delovanja - iz vidika uporabnika delujejo namreč kot "črna škatla". 
% V odziv na te pomanjkljivosti bomo definirali alternativen samokodirnik, pri katerem želimo boljši vpogled v postopek kodiranja. 
% Alternativen samokodirnik je zaradi tega narejen na osnovi naključnega gozda, saj je to model, ki praviloma deluje hitreje in omogoča uporabniku dober vpogled v delovanje.

% Samokodirnik je kompozitum dveh modelov, ki napoveduje lastne vhodne spremenljivke. 
% Njegovemu delovanju dodamo še določene omejitve ali parametre, da preslikava, ki jo izvede, ne more biti identiteta. 
% Želimo, da bi s transformacijo vhodnih spremenljivk in njihovo rekonstrukcijo samokodirnik ujel pomembnejše lastnosti podatkovne množice. 
% Rekonstruirani podatki nas razen za vrednotenje delovanja ne zanimajo - zanimajo nas transformirani podatki (običajno nižje razsežnosti) v vmesni fazi, iz katerih se da prvotno množico dobro rekonstruirati.


% ========================= %

\subsection{Definicija in vrednotenje}
% Definiramo samokodirnik ter način učenja, da jih vrednotimo z rekonstrukcijsko napako, itd.

\begin{definicija}
\label{def-samokodirnik}
% množica primerov -> množica podatkov???
Naj bo $\omega_p$ množica primerov razsežnosti $p$, ki ne vsebuje ciljne spremenljivke. Naj bosta $m_e: \omega_p \rightarrow \omega_k$ in $m_d: \omega_k \rightarrow \omega_p$ modela, kjer je $\omega_k$ množica razsežnosti $k$, ki jo imenujemo \textbf{zaloga vrednosti kode}. \textbf{Samokodirnik} je kompozitum modelov s sledečim predpisom:
\[
m_{s k} = m_d \circ m_e : \omega_p \rightarrow \omega_p .
\]
Podatkovna množica $S$ za učenje samokodirnika je oblike $S = \{(v, v), v \in \omega_p\} \subseteq \omega_p \times \omega_p$. Model $m_e$ imenujemo \textbf{kodirnik}, model $m_d$ pa \textbf{dekodirnik}.
\end{definicija}
% NOTE: pazit je treba, da bo definicija ustrezala našemu samokodirniku - ker štartamo z učenjem modela, pol ga pa predelamo

% prestavljen odstavek, da je za definicijo.
% TODO: rephrase, da je bolj jasno
% TODO: pazit, da se ne bo tekst ponavljal z ostalim v poglavju
Samokodirnik je kompozitum dveh modelov, ki napoveduje lastne vhodne spremenljivke. 
Njegovemu delovanju dodamo še določene omejitve ali parametre, da preslikava, ki jo izvede, ne more biti identiteta. 
Želimo, da bi s transformacijo vhodnih spremenljivk in njihovo rekonstrukcijo samokodirnik ujel pomembnejše lastnosti podatkovne množice. 
Rekonstruirani podatki nas razen za vrednotenje delovanja ne zanimajo - zanimajo nas transformirani podatki (običajno nižje razsežnosti) v vmesni fazi, iz katerih se da prvotno množico dobro rekonstruirati.

% postopek učenja in vrednotenja - rekonstrukcijska napaka, minimizacija funkcije izgube L(x, g(f(x)))
Samokodirnike vrednotimo glede na povprečno vrednost funkcije izgube $L$, ki ji v tem primeru pravimo \emph{rekonstrukcijska napaka}. 
Funkcija izgube je določena glede na vrsto podatkovne množice, učenje samokodirnika pa standardno poteka z minimizacijo vrednosti funkcije izgube $L(x,m_d(m_e(x)))$ na elementih učne podatkovne množice $S$. 
Samokodirnik se uči z enim algoritmom, kodirnik in dekodirnik pa nato razberemo iz samokodirnika. Kodirnika in dekodirnika torej ne učimo ločeno.

Rekonstrukcijska napaka bi bila najmanjša v primeru, ko za vsak $x \in \omega_p$ velja $x = m_d(m_e(x))$, to lahko vedno dosežemo s trivialno rešitvijo $m_e = m_d = id$, vendar s tem ne izvemo o množici ničesar novega.
Da bi se izognili trivialni rešitvi, ponavadi določimo omejitve za vmesno množico, ki to možnost preprečijo.
Najpogostejši pogoj je, da omejimo razsežnost $k$ vmesne množice $\omega_k$. 
Samokodirnik, pri katerem je množica $\omega_k$ manjše razsežnosti kot množica $\omega_p$, imenujemo \emph{nepopoln samokodirnik}. 
Upamo, da bodo izhodne spremenljivke kodirnika, ki omogočajo dobro rekonstrukcijo, dobro opisale glavne lastnosti podatkovne množice. 
V nadaljevanju se osredotočimo predvsem na nepopolne samokodirnike, vendar obstajajo tudi druge možne omejitve. 
Nekaj različic omenimo v kasnejšem razdelku, prej pa želimo opisati standarden samokodirnik, ki je sestavljen iz nevronskih mrež. 
% Z omejitvami na zakodirano plast onemogočimo, da bi bil kompozitum identiteta in upamo, da nam bo zakodirana plast povedala nekaj o množici. Omejitve so lahko različne, če preprosto omejimo število dimenzij, pa je to "undercomplete" samokodirnik.


% ========================= %

\subsection{Standarden samokodirnik}
% Opis standardnega samokodirnika/povzetek razdelka: uporablja feed-forward nevronske mreže, ki jih moramo definirati. Uči se z back propagation. 
Standardni samokodirniki so zgrajeni iz usmerjenih nevronskih mrež.
% TODO: dokončat!!!


% ========================= %

\subsubsection{Usmerjene nevronske mreže}

% Predstavitev nevronskih mrež
Nevronske mreže so eden izmed najbolj razširjenih modelov strojnega učenja (TODO: sklic na Neural networks and deep learning). Z njimi je možno dobro napovedati kompleksne množice podatkov, zahtevajo pa več procesorske moči kot večina modelov. Uporablja se jih na veliko različnih tehnoloških področjih v "big data" analizah, npr.\ finančnih trgov, baz uporabnikov, medicinskih skeniranjih, prepoznavanju pisave in govora,... 

\begin{definicija}
Naj bo $k \in \mathbb{N}$ in $\alpha$ funkcija, ki slika iz realnih števil v interval $[0,1]$. 
Funkcijo $f: [0,1]^k \rightarrow [0,1]$ s predpisom oblike $f(x) = \alpha(w\cdot x + b)$, 
kjer je $w=(w_1,\ldots,w_k) \in R^k$ vektor uteži, $b$ neko realno število in $w \cdot x$ označuje skalarni produkt vektorjev, imenujemo \textbf{nevron}. 
Konstanto $b$ imenujemo \textbf{pristranskost}, funkcijo $\alpha$ pa \textbf{aktivacijsko funkcijo}.
\end{definicija}

% TODO: definirati pojem skrite plasti!
Uporablja se lahko različne aktivacijske funkcije, standardna pa je sigmoidna funkcija $\sigma(y) = \frac{1}{1+e^{-y}}$. 
Nevronu s sigmoidno aktivacijsko funkcijo pravimo \emph{sigmoidni nevron}. Če $\sigma$ vstavimo v definicijo, dobimo za nevron $f_{\sigma}$ predpis:
\[
f_{\sigma}(x)= \frac{1}{1+e^{-\sum_{i=1}^k w_i x_i - b}}.
\]
Nevroni so sestavni deli modela nevronske mreže, ki jih združimo v večjo strukturo. 
Videli bomo, da imajo npr.\ sigmoidni nevroni lepe lastnosti, ki jih lahko dobro izkoristimo za izgradnjo modela.

\begin{definicija}
\textbf{Arhitektura usmerjene nevronske mreže} $N_{p_1,p_2,\ldots,p_l}$ je usmerjen graf, v katerem vsako vozlišče predstavlja nevron. 
Vsebuje $n= p_1+p_2+\cdots+p_l$ vozlišč, ki so razdeljena v $l$ neodvisnih, med seboj disjunktnih, množic $N_1, N_2, \ldots, N_l$. 
Povezave v grafu definiramo s predpisom, da za $i=1,2,\ldots,l-1$ velja:
\[
\forall v \in N_i, \forall w \in N_{i+1},\ v \sim w.
\]
Množici $N_1$ pravimo \textbf{vhodna plast}, množici $N_l$ pa \textbf{izhodna plast}.
\end{definicija}

\begin{figure}[h!]

\begin{center}
\includegraphics[width=0.5\textwidth]{nn_scheme}
\end{center}

\caption{Simbolična slika arhitekture usmerjene nevronske mreže (TODO: oznake)}
\end{figure}

% TODO: pregledat definicijo nevronske mreže
Velja torej, da je v arhitekturi usmerjene nevronske mreže vsako vozlišče povezano z vsemi iz prejšnje in naslednje plasti. 
Opisati moramo še, kako točno arhitektura opiše delovanje modela.

\begin{definicija}

Naj bo $N_{p_1,p_2,\ldots,p_l}$ arhitektura usmerjene nevronske mreže. Po definiciji vemo, da vsebuje $n= p_1+p_2+\cdots+p_l$ vozlišč. Pravimo, da arhitektura $N_{p_1,p_2,\ldots,p_l}$ \textbf{opiše} model $m: D_1 \times \cdots \times D_p \rightarrow D_Y$, če vsakemu vozlišču arhitekture pripada en nevron in veljajo sledeča pravila:

\begin{enumerate}
  \item $ p_1 = p$

  \item $p_l = dim(D_Y)$, kjer definiramo $dim$ s predpisom:
  \[
	  dim(D_Y) =
	  \begin{cases}
		1 &;\ D_Y \subseteq \mathbb{R} \\
		|D_Y| &;\ sicer
	  \end{cases}	
  \]% TODO: se dim pojavi še kje prej???

  \item Za vse nevrone $f^i \in N_1$ velja, da imajo $p$ razsežno domeno, njihova aktivacijska funkcija je identična preslikava, njihova pristranskost je enaka $0$, njihov vektor uteži pa je $\mathbb{I}_i$, ki je vektor z vrednostjo $1$ na $i$-tem mestu in $0$ na vseh ostalih mestih.
$$
f^i \in N_1 \Rightarrow f^i(x_1,\ldots,x_p) = id(\mathbb{I}_i \cdot (x_1,\ldots,x_p) + b) = id(x_i+0) = x_i
$$
  \item Za $j=2,\ldots,l$ za vsak nevron $f^i \in N_j$ velja, da ima domeno razsežnosti $p_{j-1}$

  \item Slika modela $m$ je definirana s predpisom $m(x) =$ \texttt{network\_predict}($x$).

  \begin{algorithm}[ht]
    \caption{Algoritem \texttt{network\_predict} napovedovanja nevronske mreže}
    \label{algoritem-neural-predict}
    \raggedright
    \textbf{Vhod: arhitektura nevronske mreže $N_{p_1,p_2,\ldots,p_l}$, primer $x$ iz podatkovne množice}  \\
    \textbf{Izhod: napoved $\hat{y}$, ki je približek ciljne spremenljivke} 
    \begin{algorithmic}[0]
	\For{$f^i \in N_1$}
		\State $\hat{y}_i \gets f^i(x)$
	\EndFor
	\For{$j = 2,\ldots,l$}
		\State $\mathit{former\_layer\_results} \gets (\hat{y}_1,\ldots,\hat{y}_{p_j-1})$
		\For{$f^i \in N_j$}
			\State $\hat{y}_i \gets f^i(\mathit{former\_layer\_results})$
		\EndFor
	\EndFor
	\State return $(\hat{y}_1,\ldots,\hat{y}_{p_l})$
    \end{algorithmic}
  \end{algorithm}

  % TODO: tole eventualno zbrisat, staro oblikovanje, algoritem je bolj naraven način za to napisat
  %\begin{itemize}
    %\item Vsak nevron $f^i \in N_1$ prejme vektor vhodnih vrednosti in jih preslika v $i$-to komponento vektorja.

    %\item Za $j=2,\ldots,l$ vsak nevron $f^i \in N_j$ prejme vektor slik, ki jih izračunajo nevroni v $N_{j-1}$

    %\item Napoved modela $m$ je vektor slik, ki jih izračunajo nevroni v izhodni plasti $N_l$
  %\end{itemize}
\end{enumerate}

\textbf{Usmerjena nevronska mreža} je model $m: D_1 \times \cdots \times D_p \rightarrow D_Y$, ki ga opiše neka arhitektura nevronske mreže, 
katere vhodna plast je sestavljena iz $p$ elementov, izhodna plast pa iz $dim(Y)$ elementov.
\end{definicija}

% TODO: poiskat primeren izrek v zvezkih za numeriko
% lastnost: majhne spremembe v utežeh/bias-u naredijo majhne spremembe v rezultatu, ker je funkcija gladka -> sklic na numeriko!!!!
% Lastnost: velikost spremembe rezultata je linearno odvisna od velikosti spremembe parametrov.
Če je nevronska mreža sestavljena iz sigmoidnih nevronov, oz.~nevronov z dovolj "lepimi" aktivacijskimi funkcijami, ima lepe lastnosti za učenje. 
Če parametre mreže, tj.~uteži in pristranskost, spremenimo za majhno količino, se tudi izhodna vrednost spremeni za majhno količino. 
To velja, ker je nevron zvezen kot funkcija uteži in pristranskosti in je velikost spremembe izhodne vrednosti linearno odvisna od velikosti sprememb uteži in pristranskosti. 
(TODO: podobna trditev je v Neural networks and deep learning, dobro bi bilo napisati vsaj idejo dokaza)

% učenje/izgradnja nevronskih mrež
To lastnost je zelo koristna pri učenju nevronske mreže. 
Parametre nevronske mreže lahko popravljamo tako, da postaja rezultat pri izbranem argumentu bolj točen, s tem pa točnosti napovedi pri drugih argumentih ne pokvarimo preveč. 
Algoritem torej prilagaja uteži in pristranskost nevronov v mreži, dokler ni razlika med napovedjo in resničnim rezultatom čim manjša. 
Pri učenju uporabimo standarden algoritem za iskanje minimuma (kot smo ga že omenili prej v tekstu: TODO uskladiti). 
Računanje gradienta funkcije izgube, ki ga algoritem potrebuje, pa je za nevronske mreže zelo zamudno - za to uporabimo postopek "vzvratnega širjenja" (ang.~backpropagation), ki je bolj učinkovit od direktnega izračuna. % TODO: vprašat ljupčota ali je to veljaven izraz - dat v emph
Bolj podroben opis nevronskih mrež in postopka, s katerim jih učimo, lahko bralec najde v (TODO: sklic na Neural networks and deep learning).

% Prednosti in slabosti nevronskih mrež
Prednosti uporabe nevronskih mrež so, da lahko uspešno dosežejo visok nivo abstrakcije - npr.\ pri prepoznavanju obrazov, avtomatiziranem branju rokopisa, razpoznavanju govora,... 
Dobro se odrežejo pri kompleksnih podatkovnih množicah z velikim številom vhodnih spremenljivk. 
Slabosti njihove uporabe pa so, da so računsko zelo zahtevne in posledično počasne, uporabnik pa težko dobi vpogled v njihovo delovanje - ponavadi se jih uporablja kot "črno škatlo".


% ========================= %

\subsubsection{Samokodirnik iz nevronskih mrež}

% TODO: tukaj je treba pojasniti, da je kodirnik posebne vrste UNM, ki napoveduje več (k) numeričnih spremenljivk hkrati. 
% Lahko bi tudi pojasnili, da je UNM kodirnika simetrična UNM dekodirnika: 
% če uporabimo notacijo iz 3.2.1, bi lahko predpisali, da veljajo enakosti |N^(e)_1| = |N^(d)_l| = p, |N^(e)_2| = |N^(d)_(l-1)|, ... |N^(e)_l| = |N^(d)_1| = k.

% uporaba točnih definicij nevronskih mrež, da se opiše struktura.
Najpogostejša implementacija samokodirnika je usmerjena nevronska mreža sestavljena iz treh ali več plasti: vhodne plasti, kode in izhodne plasti, med njimi pa so lahko še vmesne plasti. 
Kodirnik in dekodirnik sta dela te mreže, kodirnik vsebuje vhodno plast, kodo ter vmesne plasti med njima, dekodirnik pa vsebuje kodo in izhodno plast ter vmesne plasti. 
Vhodna in izhodna plast vsebujeta enako število nevronov, razsežnost kode pa je lahko različna. 
Struktura samokodirnika je prikazana na sliki 2 (TODO: dodat dinamične sklice na figure/slike)

% TODO: mal manj barvita, bolj resna shema
\begin{figure}[h!]

\begin{center}
\includegraphics[width=0.5\textwidth]{ae_scheme}
\end{center}

\caption{Shema samokodirnika}
\end{figure}

% Opis kako globina kodirnik/dekodirnika vpliva na samokodirnik.
Pri nepopolnih samokodirnikih koda vsebuje manj nevronov kot vhodna in izhodna plast. 
Če jih vsebuje več kot vhodna plast, pa rečemo, da je samokodirnik \emph{nadpopoln}. 
V tem primeru je možna identična preslikava, ki je ne želimo, zato se taki samokodirniki uporabljajo samo v posebnih primerih. 
Če kodirnik in dekodirnik ne vsebujeta skritih plasti je samokodirnik \emph{plitev}, v nasprotnem primeru pa \emph{globok}.

% TODO: še ena shema???

% opomba: z linearnimi preslikavami je to PCA
TODO: Obravnava vrst samokodirnikov, predvsem bolj posebnih vrst (sklici na vire)
% LITERATURA NEEDED

TODO: Zaključek, da se slabosti nevronskih mrež prenesejo na take samokodirnike -> alternativa.

% TODO: !!!
% PRIPOMBA od ljupčota
% 3.2.2: 
% tukaj je treba pojasniti, da je kodirnik posebne vrste UNM, ki napoveduje več (k) numeričnih spremenljivk hkrati. Lahko bi tudi pojasnili, da je UNM kodirnika simetrična UNM dekodirnika: 
% če uporabimo notacijo iz 3.2.1, bi lahko predpisali, da veljajo enakosti |N^(e)_1| = |N^(d)_l| = p, |N^(e)_2| = |N^(d)_(l-1)|, ... |N^(e)_l| = |N^(d)_1| = k.


% ========================= %

% TODO: preverit razdelke in naslove v nadaljevanju
% pazit na rdečo nit/tok besed, glede na to, da je to zdej novo poglavje, ne samo razdelek.
\section{Samokodirnik zgrajen iz naključnega gozda}

V tem poglavju bomo uvedli nov koncept samokodirnika, ki bo alternativa standardnemu pristopu. 
Z našo različico samokodirnika želimo predvsem odpraviti slabosti večine samokodirnikov. 
Cilj je torej kodiranje, ki uporabniku omogoča boljše razumevanje zakodiranih podatkov, kodirni postopek, ki ni črna škatla, in hitrejše procesiranje. 
Samokodirnik bo zgrajen na osnovi naključnega gozda in v prvem podrazdelku bomo predstavili modele odločitvenih dreves in naključnega gozda. 
Razložili bomo njihovo delovanje in prednosti, ki jih nudijo. 
Nato bomo v ločenih podrazdelkih predstavili postopek kodiranja, ki deluje na osnovi naključnega gozda, in še to, kako podatke nato dekodiramo.


% ========================= %
% TODO: bi morda združili odločitveno drevo in naključni gozd kot podrazdelka v skupni razdelek?

\subsection{Odločitveno drevo}

% Uvod/groba ideja
Odločitvena drevesa so model, pri katerem lahko uporabnik strukturo in napoved zelo dobro razume. 
Njihovo napoved se da razumeti kot zlepek konstantnih funkcij, poleg tega pa so tudi zelo učinkovita. 
Njihovo učenje zahteva zelo malo procesorskega časa in če upoštevamo vse te lastnosti, služijo kot dobro izhodišče za naš samokodirnik. 
Iščemo namreč ravno te lastnosti - dobro razumevanje in hitrost. Slabost odločitvenih dreves je v tem, da imajo preveč preprosto strukturo, 
da bi lahko napovedovala kompleksno porazdeljene množice podatkov s tako natančnostjo kot nekateri drugi modeli. 
Zaradi tega bomo najprej definirali model odločitvenega drevesa, nato pa idejo nadgradili v model naključnega gozda. 
Izkaže se namreč, da se točnost tako v splošnem izboljša, model pa še vedno vsaj delno ohrani zaželene lastnosti. (TODO: sklic na gradivo o naključnih gozdovih)

% Definicija odločitvenega drevesa
\begin{definicija} 
\textbf{Odločitveno drevo} je model, katerega delovanje opiše graf dvojiškega drevesa. 
Listi drevesa vsebujejo napovedi, v katere model preslika primere, ostala vozlišča pa vsebujejo oznako spremenljivke in mejno vrednost. 
Postopek, s katerim odločitveno drevo določi napoved, je opisan v algoritmu \ref{algoritem-predict-tree}.

% TODO: popravit definicijo okoli algoritma
\begin{algorithm}[ht]
  \caption{Algoritem napovedovanja odločitvenega drevesa}
  \label{algoritem-predict-tree}
  \raggedright
  \textbf{Vhod: odločitveno drevo $t$, primer $x$ iz podatkovne množice}  \\
  \textbf{Izhod: napoved $\hat{y}$, ki je približek ciljne spremenljivke} 
  \begin{algorithmic}[0]
	\State vozlišče $\gets 1$
	\While{list(vozlišče) = False}   \Comment{ni list, vsebuje spremenljivko in mejo}
		\State $i_{\mathrm{spremenljivka}} \gets$ spremenljivka(vozlišče)
		\State meja $\gets$ meja(vozlišče)
		\If{$x[i_{\mathrm{spremenljivka}}]$ > meja}
			\State vozlišče $\gets$ desni\_otrok(vozlišče)
		\Else
			\State vozlišče $\gets$ levi\_otrok(vozlišče)
		\EndIf
	\EndWhile
	\State $\hat{y} \gets$ napoved(vozlišče)   \Comment{vozlišče je list, vsebuje napoved}
	\State return $\hat{y}$
  \end{algorithmic}
\end{algorithm}

Naj bo $m$ odločitveno drevo, ki v $i$-tem notranjem vozlišču vsebuje $f_i$, kar je oznaka spremenljivke, in mejno vrednost $t_i$. 
Model $m$ primeru priredi napoved tako, da začne v izhodišču, tj.~vozlišču $1$, in preveri ali je vrednost spremenljivke $X_{f_1}$ pri primeru večja od meje $t_1$. 
Če je vrednost večja, potem model nadaljuje v desno poddrevo, sicer pa v levo. 
V naslednjem vozlišču spet preveri pogoj in glede na rezultat nadaljuje pot dokler ne doseže lista. 
Primeru napove vrednost, ki se nahaja v listu, kjer se pot zaključi.
% TODO: določit oznako spremenljivk. Ali je f_i okej? Predlog je bil X_i, ampak potem ne velja, da i-to vozlišče vsebuje X_i
% popravit tudi na sliki drevesa

% TODO: uskladiti oznake spremenljivk:
% - štetje vozlišč začnemo pri 1!
% jasno/pravilno napisat odstavek poleg algoritma
% popravit primer, da se ujema
\end{definicija}

(TODO: citat o tem, kako se dreves učijo/gradijo, npr.\ Understanding random forests: from theory to practice)
Zapisali smo definicijo odločitvenega drevesa, za lažje razumevanje pa opišimo delovanje modela še na preprostem primeru.

\begin{primer}
% TODO: dinamičen sklic na sliko
Na sliki \ref{def-odlocitvenega-drevesa} je primer grafa odločitvenega drevesa. 
Denimo, da to drevo prejme primer $x=(1,1)$, tj. $X_1=1$ in $X_2=1$. 
Ker velja $f_1 = 2$, v prvem vozlišču preverimo vrednost druge spremenljivke. 
Vrednost spremenljivke $X_{2}$ je $1$ in ker je manjša od mejne vrednosti $t_0=1.5$, postopek nadaljujemo v levem poddrevesu. 
S tem prispemo v list in za primer napovemo vrednost $0$.

\begin{figure}[h!]
\setlength{\unitlength}{1cm}

\begin{center}
\begin{picture}(4,5.5)
% točke
\put(2,5){\circle*{0.1}}
\put(1,3){\circle*{0.1}}
\put(3,3){\circle*{0.1}}
\put(2,1){\circle*{0.1}}
\put(4,1){\circle*{0.1}}

% črte
\put(2,5){\line(1,-2){1}}
\put(2,5){\line(-1,-2){1}}
\put(3,3){\line(1,-2){1}}
\put(3,3){\line(-1,-2){1}}


% oznake
\put(2.2,5){$f_1=2,\ t_0=1.5$}
\put(3.2,3){$f_2=1,\ t_1=0$}

\put(0.8,2.4){$0$}
\put(1.8,0.4){$3$}
\put(3.8,0.4){$4$}
\end{picture}
\end{center}

\caption{Primer odločitvenega drevesa}\label{def-odlocitvenega-drevesa}
\end{figure}

Če bi drevo prejelo primer $x=(1,2)$, tj.~$X_1=1$ in $X_2=2$, pa bi iz korena nadaljevali v desno poddrevo, saj je vrednost druge spremenljivke večja od meje $t_0=1.5$. 
Ker velja $f_2 = 1$, v naslednjem vozlišču preverimo vrednost prve spremenljivke, k. 
Vrednost prve spremenljivke $X_1 = 1$ je višja od mejne vrednosti $t_1=0$. 
Postopek tako nadaljujemo v desnem poddrevesu, ki je list, in zato za primer napovemo vrednost $4$.
\end{primer}

% TODO: razdeliti odstavek na sredi, da se doda razdelek o naključnem gozdu

% Argument za združevanje dreves v naključni gozd. Morda izpeljava ali pa citat, da se kvaliteta napovedi izboljša.
Odločitveno drevo je dokaj preprost model, ki v splošnem ne more natančno opisati preveč kompleksno porazdeljenih podatkov. 
V primeru kompleksnih podatkov namreč pogosto pride do preprileganja - 
globoko, močno razvejano drevo (preveč) podrobno opiše podatke učne množice, s tem pa izgubi natančnost na ostalih primerih iz porazdelitve. 

\subsection{Naključni gozd}

Natančnost modelov lahko izboljšamo z združevanjem v ansamble (TODO: citat!!! npr.\ Understanding random forests: from theory to practice)
Zelo razširjena metoda za združevanje dreves v ansamble pa je model odločitvenega gozda. 
V splošnem se izkaže za zelo uspešno in bolj natančno kot posamezno odločitveno drevo. 
(TODO: citat! npr.\ Understanding random forests: from theory to practice, vsebuje del o zgodovinskem razvoju/utemeljitvi naključnega gozda)

\begin{definicija}
\textbf{Ansambel dreves} je model, ki je sestavljen iz več odločitvenih dreves. 
Če je ciljna spremenljivka numerična, je napoved ansambla dreves povprečje napovedi posameznih dreves. 
Če je ciljna spremenljivka diskretna, pa je napoved ansambla določena izmed napovedi odločitvenih dreves tako, da se izbere napoved, ki jo napove največje število odločitvenih dreves.
% TODO: kako definiramo modus? -> vprašat
% TODO: spremenit definicijo v enačbe, ne tekst
\end{definicija}

Poudariti je treba, da je ansambel posebna vrsta modela. 
Definirali smo ansambel dreves, lahko pa gradimo tudi ansamble drugih vrst modelov. 
Ansamble bi lahko obravnavali kot celo zvrst modelov, ki jih zgradimo z združevanjem različnih vrst posameznih modelov. 
S tem želimo izboljšati točnost in zmanjšati preprileganje. (TODO: sklic na gradivo o ansamblih/vrste ansamblov) Naključni gozd je posebna vrsta ansambla dreves.

\begin{definicija}
Naj bo $S \subseteq \omega$ podatkovna množica razsežnosti $p$. 
\begin{algorithm}[ht]
	\caption{Algoritem konstrukcije modela naključnega gozda}
	\label{algoritem-construct-RF}
	\raggedright
	\textbf{Vhod: podatkovna množica $S$, število odločitvenih dreves $q$, število analiziranih spremenljivk $m$}  \\
	\textbf{Izhod: model naključnega gozda $m_{rf}$} 
	\begin{algorithmic}[0]
	  \State $m_{rf} \gets $ init\_random\_forest()
	  \ForAll{$i \in \{1,\ldots,q\}$}
  ¸	\State $S' \gets [\ ]$
	  \ForAll{$j \in \{1,\ldots,n\}$}
		  \State $x \gets$ random\_element($S$)
		  \State $S'$.append($x$)
	  \EndFor
	  \State $t_i \gets $ train\_random\_tree($S'$, $m$)
	  \State $m_{rf}$.add\_tree($t_i$)
	  \EndFor
	\end{algorithmic}
\end{algorithm}

\textbf{Naključni gozd} je ansambel dreves, ki ga konstruiramo s postopkom opisanim v algoritmu \ref{algoritem-construct-RF} in za katerega veljata sledeči pravili:

\begin{enumerate}
\item Vsako odločitveno drevo se zgradi iz množice naključno izbranih primerov iz podatkovne množice $S$.

\item Na vsakem koraku gradnje drevesa je za spremenljivko, ki določa vejitev v vozlišču, določena optimalna spremenljivka izmed množice $m$ različnih naključno izbranih spremenljivk. Algoritem $\mathrm{train\_random\_tree}$ označuje tako prilagojeno različico standardnega postopka izgradnje dreves (TODO: sklic na algoritem za učenje dreves). Osnoven algoritem se od $\mathrm{train\_random\_tree}$ razlikuje v tem, da ob vsaki vejitvi izbira spremenljivko iz nabora vseh spremenljivk.
\end{enumerate}

Ponavadi velja $m < p$, če velja $m=p$, pa ta algoritem imenujemo vrečenje (ang.~bagging).
\end{definicija}

% TODO: zbrisat, če je odveč
%\begin{definicija}
%Naj bo $S \subseteq \omega$ podatkovna množica razsežnosti $p$. \textbf{Naključni gozd} je model, ki je sestavljen iz več odločitvenih dreves, ki so zgrajena s podatkovno množico $S$ in naključnim izbiranjem skupine spremenljivk za razvejitev. Napoved določi z združevanjem napovedi odločitvenih dreves. Postopek izgradnje naključnega gozda opiše sledeči algoritem:

% ====

%Postopek takšnega naključnega izbiranja spremenljivk (ali pogosteje primerov) imenujemo \textbf{vrečenje} (ang.~bagging). Napoved naključnega gozda se v primeru klasifikacije določi z ''glasovanjem'' odločitvenih dreves, kjer je izbrana napoved, ki jo izbere največ dreves. V primeru regresije pa se napoved določi kot povprečna vrednost napovedi odločitvenih dreves.
% TODO: algoritem za prediction???
%\end{definicija}
% TODO: pri odstavku o diskretnih in zveznih spremenljivkah definirat še klasifikacijo in regresijo

% Prednosti: zelo jasno berljiv model. Napoved lahko jasno razumemo, procesiranje vseeno hitro. Dosega dobro natančnost v splošnem.
Prednosti naključnega gozda so, da model v splošnem dosega dobro natančnost, pogosto že preden parametre prilagodimo primeru, in sorazmerno hitro delovanje. 
Hitrost delovanja sledi iz tega, da je izgradnja odločitvenih dreves hiter postopek in ponovitev ni preveč, saj število dreves $q$ ni zelo visoko, standardno se vzame npr.\ $q = 100$. 
Izračun napovedi iz podobnega razloga ne zahteva veliko časa - potreben je namreč pregled $q$ dreves in združitev njihovih napovedi. 
Delovanje naključnega gozda pa lahko uporabnik dobro razume, ker model vsebuje odločitvena drevesa. 
Pri delovanju se da namreč pregledati napoved vsakega posameznega drevesa, napovedi pa se združijo na jasen način. 
Glede na te lastnosti je naključni gozd primeren model za uporabo pri alternativni različici samokodirnika.


% ========================= %

\subsection{Kodirnik}

Naključni gozd lahko naučimo in uporabimo za napovedovanje lastnih vhodnih spremenljivk. 
Poudariti je treba, da morajo naključni gozd in drevesa, ki jih vsebuje, napovedovati vektorje vrednosti vseh vhodnih spremenljivk, namesto da bi npr.\ 
posamezna drevesa napovedovala vrednosti posameznih spremenljivk, ki bi se potem združile. 
Tak primer se ne bi ujemal z našo definicijo ansambla in posledično naključnega gozda, zanj pa v splošnem tudi ne bi veljale lastnosti, s katerimi smo utemeljili naključni gozd npr.\ manjše preprileganje. 
% ki so bile motivacija za uvedbo?
Če bi uspeli naključni gozd razdeliti na dva dela, bi lahko model razumeli kot samokodirnik, vendar bomo model naključnega gozda raje vzeli za izhodišče in na tej osnovi sestavili nov samokodirnik. 
Prvi izziv, s katerim se moramo soočiti, je, kako bi iz naključnega gozda ustvarili čim boljše kodiranje.

\begin{definicija}
\label{def-pripadnost-listu}
Naj bo $T$ odločitveno drevo zgrajeno na podatkovni množici $S \subseteq \omega$ razsežnosti $p$ in $x=(x_1,\ldots,x_p) \in S$. 
Naj bo $l$ list iz $T$, do katerega vodi pot $q$ skozi vozlišča $v_1, v_2, \ldots, v_k, l$. 
Za bolj jasno formulacijo označimo še vozlišče $v_{k+1} = l$.
Za $i=1,2,\ldots,k$ definiramo logično izjavo $q_i$ s sledečim predpisom:
\[
q_i(l,x) =
\begin{cases}
x_{f_{v_i}} > t_{v_i} &;\ v_{i+1} \text{ je element desnega poddrevesa od } v_i \\
x_{f_{v_i}} \leq t_{v_i} &;\ v_{i+1} \text{ je element levega poddrevesa od } v_i\ \ .
\end{cases}
\]
Definiramo še logično formulo $Q(l,x)=q_1(l,x) \land q_2(l,x) \land \cdots \land q_k(l,x)$, ki je konjunkcija vseh izjav $q_i$.
Pravimo, da primer $x$ \textbf{pripada} listu $l$, če velja logična formula $Q(l,x)$.
\end{definicija}
% TODO: je logična formula pravilen izraz?

Vsak list odločitvenega drevesa opiše neko lastnost podatkovne množice. Množico jasno razdeli na dva dela - na tiste primere, ki listu pripadajo, in tiste, ki mu ne.
Primeri, ki listu pripadajo, pa morajo ustrezati množici pogojev, ki sestavljajo formulo $Q(l,x)$, in so si tako v nekaterih lastnostih podobni. % TODO: uštulit izjavo, da te pogoji tvorijo pot do lista? prebrat še enkrat vse skupej za preverit, če je dovolj jasno
Porodi se ideja za kodiranje: iz gozda izberemo množico ``dobrih'' listov $l_1, l_2, \ldots, l_c$, za katere želimo, da bi skupaj čim bolje zajeli lastnosti množice podatkov.

% definicija kodirni vektor + kako deluje kodirnik na osnovi tega kodirnega vektorja
\begin{definicija}
\label{def-kodiranje}
	% TODO: oz. njihove oznake?? je tu nujno??
	Vektor $\kappa=(l_1,\ldots,l_c)$, katerega elementi so listi dreves naključnega gozda (oz.~njihove oznake), imenujemo \textbf{kodirni vektor}.
	Kodirnik $\phi_\kappa: \omega \rightarrow \{0,1\}^c$, ki deluje na osnovi kodirnega vektorja $\kappa=(l_1,\ldots, l_c)$, definiramo s predpisom $\psi_\kappa(x) = (b_1, b_2, \ldots, b_c)$, kjer za $i=1,2,\ldots,c$ velja:
	$$
	b_i = 
	\begin{cases}
	1 &;\ \text{ če je formula } Q(l_i,x) \text{ resnična} \\
	0 &; \text{ sicer}\ \ .
	\end{cases}
	$$
\end{definicija}
Primere torej zakodiramo z dvojiškimi vrednostmi glede na to, katerim listom pripadajo. Dolžina zakodirane predstavitve primerov je $c$, enako kot število listov.

% TODO: preverit algoritem + dodat komentarje
\begin{algorithm}[h!]
  \caption{Algoritem konstrukcije kodirnega vektorja iz modela naključnega gozda}
  \label{algoritem-find-encoding}
  \raggedright
  \textbf{Vhod: naključni gozd $m_{rf}$, razsežnost kode $d_{code}$, mera kvalitete listov $\rho$, mera podobnosti listov $sim$, meja dovoljene podobnosti $t_{sim}$}  \\
  \textbf{Izhod: kodirni vektor $\kappa$} % TODO: preimenovat kodirni vektor, morda je lahko v_K ?
  \begin{algorithmic}[0]
	\State $\kappa = [\ ]$
	% we want to init K
	% alternativa: sproti brišemo drevesa/liste iz množice, da lahko v drugi zanki vzamemo preostanek?
	\For{$t$ in $m_{rf}$.trees}
		\For{$leaf$ in $t$.leaves()}
			\If{length($\kappa$) $< d_{code}$}
				\State $\kappa$.append($leaf$)
			\EndIf
		\EndFor
	\EndFor
	\For{$t$ in $m_{rf}$.trees}
		\For{$l_{new}$ in $t$.leaves()}
			\If{$l_{new} \notin \kappa $}
				\State $\kappa$.sort\_by\_quality()
				\State $l_{last}$ = $\kappa$.pop()
				% TODO: premislit ali je boljši način za reševat podobnost
				\If{$\rho(l_{new}) > \rho(l_{last})$}
					\If{$\forall l \in \kappa : sim(l, l_{new}) < t_{sim}$}
						\State $\kappa$.append$(l_{new}$)
					\Else
						\State $\kappa$.append$(l_{last}$)
					\EndIf
				\EndIf
			\EndIf
		\EndFor
	\EndFor	
	\State return $\kappa$
  \end{algorithmic}
\end{algorithm}

Z algoritmom \ref{algoritem-find-encoding} konstruiramo kodirni vektor, ki ga nato uporabimo v algoritmu \ref{algoritem-encode}, 
da dobimo kodirnik kot je opisan v definiciji \ref{def-kodiranje}.
V algoritmu \ref{algoritem-find-encoding} želimo konstruirati dober kodirni vektor $\kappa$. Postopek poteka tako, da pregledamo vsa drevesa v gozdu. 
Pri vsakem drevesu pregledamo vse liste in za posamezen list $l_{new}$ storimo sledeče: 
če kodirni vektor še ne vsebuje dovolj elementov, list dodamo med kandidate za kodirni vektor, sicer preverimo druge kriterije, da odločimo, ali je $l_{new}$ dober kandidat za kodirni vektor. 
Z mero kvalitete $\rho$ primerjamo, ali je $l_{new}$ bolj kvaliteten kandidat od najslabšega trenutno vključenega v kodirni vektor. 
Če je $l_{new}$ bolj kvaliteten kot vsaj en izmed trenutnih kandidatov in ni preveč podoben ostalim že vključenim kandidatom kodirnega vektorja, ga dodamo v kodirni vektor $\kappa$ namesto najslabšega kandidata.

% Kako pa določimo, kateri listi so "dobri"? Glede na mešanico kriterijev: število pokritih primerov, lokalno točnost, podobnost med listi - ne želimo, da se preveč prekrivajo

% Splošen razmislek o dobrih kandidatih: podobnost, quality itd.
Pojavi se ključno vprašanje, kako določimo, kateri listi so dobri kandidati. Ne želimo, da bi si bili kandidati v kodirnem vektorju $\kappa$ med seboj preveč podobni. 
Če dva lista v kodirnem vektorju opišeta podobno (ali enako) lastnost, bi lahko enega izmed njiju odstranili iz nabora listov za kodirni vektor brez škode, in tako dobili kodirni vektor manjše razsežnosti. 
Ker je razsežnost kodirnega vektorja fiksirana, pa v primeru, da sta si dva lista med seboj preveč podobna, enega raje zamenjamo z nekim drugim listom, tudi če je nadomestni list glede na ostala merila slabši.
Zato vpeljemo mero podobnosti $sim$ in podobnost listov preverjamo v algoritmu preden naredimo zamenjavo. Če je nov kandidat preveč podoben nekemu že vključenemu, ga ne dodamo.
Vpeljati moramo pa tudi neko mero kvalitete listov, ki za posamezen list neodvisno od ostalih listov opiše, ali je dober kandidat.

% opis mere podobnosti
Mera podobnosti $sim$ liste primerja glede na primere, ki jim pripadajo. 
Če listoma $l_1$ in $l_2$ iz množice učnih primerov pripada enaka podmnožica primerov, lahko sklepamo, da lista opišeta zelo podobno ali celo enako lastnost.
Definiramo preslikavo $\sigma_{\mathit{pripadnost}}: V(G) \rightarrow \mathcal{P}(S)$, s katero list predstavimo z množico primerov, ki mu pripadajo.
Preslikava list $l$ preslika v podmnožico $\sigma_{\mathit{pripadnost}}(l) = \{x\ | formula Q(l,x) je resnična \}$.
Mero podobnosti definiramo s sledečim predpisom:
\[
	sim(l_1, l_2) = \frac{|\sigma_{pripadnost}(l_1) \cap \sigma_{pripadnost}(l_2)|}{|\sigma_{pripadnost}(l_1) \cup \sigma_{pripadnost}(l_2)|}.
\]
% TODO: preveriti, ali v skripti mera podobnosti res deluje tako. najbrž ne -> fix it!!!
Kot mero torej vzamemo razmerje med številom primerov, ki pripadajo obema listoma hkrati, in številom vseh primerov, ki pripadajo enemu ali drugemu listu.

% opis mere kvalitete
% TODO: uskladiti oznake in poimenovanja: ang vs. slo, dolžino imen itd.
Definirati moramo še mero kvalitete lista $\rho$. 
Listi, ki vsebujejo večji delež primerov opišejo pogostejšo lastnost, ki jo lahko zato razumemo kot bolj pomembno. 
Drug podatek, ki ga v listih lahko opazujemo, je lokalna natančnost napovedi $\mathit{accuracy}$.
Pove nam, kako natančna je napoved, ki jo drevo priredi primerom, ki pripadajo listu.
Mero kvalitete tako v splošnem definiramo kot linearno kombinacijo teh dveh vrednosti:
\[
\rho_{\gamma}(l) = \gamma \frac{|\sigma_{\mathit{pripadnost}}(l)|}{|S|} + (1-\gamma) \mathit{accuracy}(l)
\]
\label{mera-kvalitete}
Mera kvalitete je odvisna od parametra $\gamma \in [0,1]$.
Če privzamemo, da je vrednost $\gamma$ enaka $1$, je mera kvalitete $\rho_1(l)$ enaka deležu listu $l$ pripadajočih primerov iz učne množice.
Analogno lahko privzamemo, da je vrednost $\gamma$ enaka $0$, v tem primeru, pa je mera kvalitete $\rho_0(l)$ enaka lokalni natančnosti $\mathit{accuracy}(l)$ v listu $l$.
Zaenkrat bomo privzeli, da je mera kvalitete v besedilu uporabljena mera kvalitete s parametrom $\gamma=0.5$, saj želimo, da se upoštevata oba člena.
V poglavju o vrednotenju delovanja samokodirnika bomo preverili, kako dobro deluje samokodirnik pri različnih nastavitvah parametra $\gamma$,
med drugim tudi zato, da ugotovimo, če v splošnem obstaja najboljša nastavitev, ki bi jo nato nastavili kot privzeto.

% TODO: pozorno prebrati ta razdelek - da niso vključeni popravki pokvaril poteka besedila
Opisali smo postopek s katerim določimo kodirni vektor. Zapisati pa moramo še postopek delovanja kodirnika na osnovi tega kodiranja.
Algoritem \ref{algoritem-encode} opiše delovanje kodirnika kot je definiran v definiciji \ref{def-kodiranje}. 
Kodirni vektor, ki ga konstruiramo z algoritmom \ref{algoritem-find-encoding} mu podamo kot argument.
Opiše torej, kako kodirnik $\phi_K$, ki deluje na osnovi kodirnega vektorja $\kappa$, zakodira podatkovno množico $S$. 
Z zanko gremo čez podatkovno množico in vsakemu primeru priredimo vektor vrednosti, kot je določen v definiciji \ref{def-kodiranje}.
Za vsak primer iz množice $S$ gremo z zanko čez vse elemente kodiranja. 
Če primer pripada $i$-temu listu kodirnega vektorja, za $i$-ti člen zakodirane predstavitve določimo $1$, sicer za $i$-ti člen zakodirane predstavitve določimo $0$.
Tako zakodirane primere združimo v zakodirano podatkovno množico $S'$, ki jo algoritem vrne.

% algoritem delovanja kodirnika
\begin{algorithm}[ht]
  \caption{Algoritem kodiranja primera z danim kodiranjem}
  \label{algoritem-encode}
  \raggedright
  \textbf{Vhod: primer $x$ iz podatkovne množice, kodirni vektor $\kappa$}  \\
  \textbf{Izhod: zakodiran primer $x'$} 
  \begin{algorithmic}[0]
	\State $x'$ $\gets [\ ]$
	\For{leaf in $\kappa$} % TODO: lepši zapis
		\If{$x \in$ leaf}
			\State $x'$.append($1$)
		\Else
			\State $x'$.append($0$)
		\EndIf
	\EndFor
	\State return $x'$
  \end{algorithmic}
\end{algorithm}

% TODO: prebrat cel razdelek kot celoto
Podrobno smo opisali delovanje kodirnika, ki je del samokodirnika, ki ga konstruiramo. 
Da bo določen celoten samokodirnik, moramo konstruirati in opisati še dekodirnik.


% ========================= %

\subsection{Dekodirnik}

% fuj, TODO: spolirat definicijo.
\begin{definicija}
	\label{def-dekodiranje}
	Dekodirnik $\theta: \{0,1\}^c \rightarrow \omega$ je preslikava, ki preslika zakodiran primer nazaj v element množice $\omega$.
\end{definicija}
Če je dekodirnik nenatančen, ne moremo biti prepričani, da smo izbrano kodiranje dobro ovrednotili, saj so napake lahko krivda dekodirnika in ne pomanjkljivosti kodiranja.
Zato je naš cilj konstruirati čim bolj natančen dekodirnik, ki zakodiran primer preslika v dober približek njegove prvotne vrednosti.
Pri konstrukciji se bomo cel čas opirali na kodirni vektor, katerega elementi so listi, ki opišejo kodiranje.
Na razpolago imamo dva glavna podatka - poti do listov v kodirnem vektorju, ki vsebujejo pogoje o vrednosti primerov, in v listih shranjene napovedi. 

% napeljemo na SAT formulacijo
Najprej se bomo posvetili temu, kaj lahko o vrednosti prvotnega primera ugotovimo iz poti do listov, ki jim primer pripada.
Kot smo povedali v definiciji \ref{def-pripadnost-listu}, velja, da primer $x$ iz podatkovne množice pripada listu $l$ natanko tedaj, ko velja pogoj $Q(l,x)$.
Naj bo $\kappa=\{l_1, l_2, \ldots, l_c\}$ kodirni vektor.
Za vsak $x \in \omega$ za nek $j \in \{1,2,\ldots,c\}$ velja bodisi $Q(l_j,x)$ bodisi $\lnot Q(l_j,x)$.
Z upoštevanjem vrednosti zakodiranega primera, ki je argument podan dekodirniku, lahko ugotovimo, katera izmed teh dveh trditev je resnična.
Tako dobimo nabor $c$ logičnih izjav, ki veljajo za primer $x$.
Za primer $x=(x_1,\ldots,x_p)$ posledično velja tudi konjunkcija teh logičnih izjav, ki jo označimo z $\Delta_{l_1,\ldots,l_c}(x_1,\ldots,x_p)$.

% TODO: reread in urejanje
% mal spravit tole v red
Želimo poiskati nabor vrednosti, za katerega bo veljala formula $\Delta_{l_1,\ldots,l_c}(x_1,\ldots,x_p)$, saj sklepamo, da bo dobra aproksimacija primera $x$.
Izkaže se, da v logiki obstaja znan problem, ki je formuliran na podoben način.

% definicija SAT problema
\begin{definicija}
	Naj bo $\phi(x_1,\ldots,x_k)$ logična formula.
	Če obstaja tak vektor logičnih vrednosti $(v_1, \ldots, v_k)$, da je izraz $\phi(v_1, \ldots, v_k)$ resničen,
	pravimo, da je formula $\phi$ \textbf{zadovoljiva} (ang.~satisfiable).
	Problem, ki se ukvarja s tem, ali je logična formula zadovoljiva, imenujemo SAT problem. % TODO: citat
\end{definicija}
% z rešitvijo SAT problema si lahko pomagamo, ampak je slow as FUCK.
Če najdemo vektor logičnih vrednosti, pri katerem logična formula drži, smo pokazali, da je formula zadovoljiva.
Ponavadi se SAT problem rešuje z iskanjem takega vektorja in tak algoritem lahko izkoristimo za rekonstrukcijo primera $x$ iz logične formule $\Delta_{l_1,\ldots,l_c}(x_1,\ldots,x_p)$.
V splošnem je reševanje SAT problema žal zelo neučinkovito - problem je NP-poln (TODO:citat).
Pri nekaterih podproblemih pa se da SAT problem reševati mnogo hitreje. 
V ta namen bomo uvedli posebno vrsto logičnih formul.

% vpeljemo KNO formule
\begin{definicija}
	\textbf{Literal} je logična spremenljivka ali negacija logične spremenljivke.
\end{definicija}

\begin{definicija}
	\textbf{Klavzula} je disjunkcija enega ali več literalov.
\end{definicija}

\begin{definicija}
	Za logično formulo $\phi$ pravimo, da je v \textbf{konjunktivni normalni obliki}(angl. Conjunctive Normal Form), 
	oz.~da je KNO formula, če je konjunkcija ene ali več klavzul.
\end{definicija}

\begin{primer}
	Naj bodo $x,y$ in $z$ logične spremenljivke. Izraza $x$ in $\lnot y$ sta literala, $x \lor \lnot y$ pa je klavzula.
	Logična formula $(x \lor \lnot y) \land (\lnot x \lor y \lor \lnot z) \land (x \lor z)$ je v konjunktivni normalni obliki.
\end{primer}

% SAT problem za KNO formule se da reševati uredu z DPLL - torej želimo KNO formule. Premislimo, da je naša formula v KNO
Za KNO formule lahko SAT problem rešujemo z DPLL (Davis--\-Putnam--\-Logemann--\-Loveland) algoritmom (TODO: sklic), kar je mnogo bolj učinkovito od reševanja v splošnem. %TODO: dodat break v ime DPLL
Videli bomo, da je $\Delta_{l_1,\ldots,l_c}(x_1,\ldots,x_p)$ KNO formula in lahko tako na njej uporabimo DPLL algoritem.
Povedali smo, da je $\Delta_{l_1,\ldots,l_c}$ konjunkcija $c$ izjav, ki so za $j \in \{1,2,\ldots,c\}$ bodisi $Q(l_j,x)$ bodisi $\lnot Q(l_j,x)$.
Pokazati moramo, da so izjave vsebovane v konjunkciji klavzule ali pa KNO formule - saj je v tem primeru tudi $\Delta_{l_1,\ldots,l_c}$ KNO formula.
Spomnimo se definicije \ref{def-pripadnost-listu} - izraz $Q(l_j,x)$ je konjunkcija izrazov $q_i(l_j,x)$.
%
\begin{opomba}
	Izraze $q_i(l_j,x)$ lahko razumemo kot literale.
	Definirani so kot $x_{f_{v_i}} > t_{v_i}$ ali $x_{f_{v_i}} \leq t_{v_i}$.
	Definiramo logično spremenljivko $r_{f_{v_i}} = x_{f_{v_i}} > t_{v_i}$ in opazimo, 
	da je izraz $q_i(l_j,x)$ enak tej logični spremenljivki ali njeni negaciji, torej je literal.
\end{opomba}
% TODO: premislit ali je res RES pravilno implementirano tole
% TODO: premislit, ali se da to povedati bolj preprosto.
% 
Izraz $Q(l_j,x)$ je torej konjunkcija literalov.
Posamezni literali pa so klavzule, saj so disjunkcija enega literala, in zato je izraz $Q(l_j,x)$ tudi konjunkcija klavzul.
To je natanko definicija KNO formule in izraz oblike $Q(l_j,x)$ je torej KNO formula.

% obravnava zanikanih členov
Pokazati moramo še to, da je tudi izraz oblike $\lnot Q(l,x)$ KNO formula ali klavzula.
Negacija konjunkcije $q_1(l,x) \land q_2(l,x) \land \ldots \land q_k(l,x)$ je disjunkcija $\lnot q_1(l,x) \lor \lnot q_2(l,x) \lor \ldots \lor \lnot q_k(l,x)$.
Če literal zanikamo, še vedno ostane literal, zato z negacijo konjunkcije literalov dobimo disjunkcijo literalov, oz. klavzulo.
Ugotovili smo, da so vsi izrazi v $\Delta_{l_1,\ldots,l_c}$ KNO formule ali klavzule in je zato tudi konjunkcija teh izrazov KNO formula.
Formulo $\Delta_{l_1,\ldots,l_c}(x_1,\ldots,x_p)$ lahko torej podamo DPLL algoritmu, da najdemo vrednosti argumentov, pri katerih formula velja.

% Rešujemo torej DPLL, imamo pa še en podatek - shranjene napovedi, ki ga definitivno želimo izkoristiti (celo mera kvalitete je zasnovana glede na to)
Nismo še upoštevali podatka, da odločitveno drevo primerom, ki pripadajo določenemu listu, napove vrednost.
Če za liste kodirnega vektorja pripadajočim primerom napovedane vrednosti shranimo, lahko pri konstrukciji dekodirnika tudi te podatke preprosto uporabimo.
Pričakujemo, da so shranjene napovedi sorazmerno natančne, saj je natančnost napovedi glavni cilj pri izgradnji odločitvenega drevesa.
Premisliti želimo prednosti in slabosti uporabe shranjenih napovedi v primerjavi z DPLL algoritmom, zanima pa nas tudi, kako bi obe informaciji izkoristili v postopku konstrukcije dekodirnika.

% ni nujno, da iz DPLL-a dobimo vse vrednosti. 
% Če je več možnih vektorjev, ki zadovoljijo formulo podano DPLL algoritmu, ni dobrega zagotovila za natančnost napačnega vektorja
% hitreje je uporabiti shranjene napovedi
% za nekatere primere nimamo shranjenih napovedi
% izkoristimo lahko sort of kombinacijo: napoved + pot do listov, katerim primer pripada.
Algoritem DPLL vrne en možen nabor vrednosti, pri katerem velja logična formula, ponavadi pa to ni edina možna rešitev.
Nimamo zagotovila, da je rešitev DPLL algoritma zares bližje prvotni vrednosti primera kot shranjena napoved, čeprav shranjena napoved morda ne bi bila veljavna rešitev algoritma.
Pri reševanju SAT problema se lahko zgodi, da je vrednost fiksirana zgolj za nekaj spremenljivk - če želimo vrniti primer, je treba dopolniti tudi vrednosti ostalih spremenljivk, npr. z naključnim izbiranjem.
Pri uporabi shranjenih napovedi pa dobimo napoved za vrednosti vseh spremenljivk.
Uporaba shranjene napovedi je tudi hitrejša, saj zahteva samo to, da iz zakodiranega primera razberemo, kateremu listu pripada in nato klic shranjene napovedi tega lista.
Problem z uporabo shranjene napovedi pa nastopi pri primerih, ki ne pripadajo nobenemu listu iz kodirnega vektorja.

% TODO: OPOMBA!!! - mi uporabljamo faking prirejen DPLL algoritem, moramo ga poimenovat, ni samo basic verzija

% dobimo jasno delitev primerov: tiste, ki pripadajo kakšnemu listu in tiste, ki nobenemu. To utemeljimo
Če upoštevamo ta razmislek, je smiselno primere razdeliti na dve skupini in pri vsaki ravnati drugače.
\begin{enumerate} % TODO: popravit
	\item Za primere, ki ne pripadajo nobenemu listu iz kodirnega vektorja,
	uporabimo logično formulo $\Delta_{l_1,\ldots,l_c}$, za katero vemo, da je veljala za prvotni primer.
	S pomočjo prilagojenega postopka DPLL algoritma poiščemo primer, pri katerem te formula velja, in ga izberemo kot vektor, ki ga bo vrnil dekodirnik.

	\item Za primere, ki pripadajo vsaj enemu listu iz kodirnega vektorja, uporabimo shranjeno napoved primernega lista.
	Uporabiti DPLL algoritem hkrati bi bilo zamudno in pričakujemo, da s tem rezultata ne bi bistveno izboljšali, vseeno pa lahko uporabimo podatke o poteh do listov, katerim primer pripada.
	Če primer listu $l_j$ iz kodirnega vektorja, vemo, da za primer velja logična formula $Q(l_j,x) = q_1(l,x) \land q_2(l,x) \land \cdots \land q_k(l,x)$. % TODO: so v takem primeru \ldots ali \cdots???
	Če upoštevamo izraze $q_i(l,x)$, lahko za rekonstruirani primer fiksiramo vrednosti $k$ spremenljivk.
	Za te vrednosti vemo, da so pravilne, saj so podatki o pripadnosti listom bili določeni na osnovi prvotnega primera.
	Tako lahko z upoštevanjem dejstva, katerim listom primer pripada, določimo vrednosti nekaterih spremenljivk, za določiti vrednosti preostalih spremenljivk pa uporabimo shranjene napovedi.
	Ker lahko en primer pripada več listom kodirnega vektorja, lahko zanj velja več shranjenih pripovedi.
	V tem primeru se lahko odločimo, ali napovedi združimo in uporabimo njihovo povprečje, ali uporabimo zgolj eno.
	% Privzeto delovanje dekodirnika je, da se uporabi zgolj ena napoved - tista, ki je shranjena v zadnjem primernem listu, ki ga algoritem najde. % TODO: je treba tukej napisat, da povprečje ni dalo izboljšave? Je to primerno mesto za to napisat?
\end{enumerate}

V algoritmu \ref{algoritem-decode} je zapisan postopek rekonstrukcije zakodirane podatkovne množice.
Algoritem pregleda vse primere v množici in sledi načrtu za dekodiranje, ki smo jih opisali.
Za primer preveri, ali pripada kateremu listu kodirnega vektorja $\kappa$, in shrani vse liste, ki jim primer pripada, v seznam prediction\_candidates.
Če pripada vsaj enemu listu, tj.~seznam prediction\_candidates ni prazen, se rekonstrukcijo prvotne vrednosti primera določi z metodo $select\_prediction$, ki združi primerne napovedi.
Če primer ne pripada nobenemu listu, algoritem pretvori poti do listov kodirnega vektorja v logične izjave in jih združi v formulo $\Delta_{l_1,\ldots,l_c}$.
Nato pa algoritmu $DPLL\_example$ poda to formulo in rekonstrukcijo $\hat{x}$ določi kot vektor, ki ga vrne $DPLL\_example$ algoritem. % TODO: popravit tale stavek
% oh boi OH BOI... te oznake se z implementacijo sploh ne poklapajo - za preverit - TODO

\begin{algorithm}[h!]
	\caption{Algoritem dekodiranja zakodiranega primera}
	\label{algoritem-decode}
	\raggedright
	\textbf{Vhod: zakodiran primer $x'$, kodirni vektor $\kappa$, razsežnost kodiranja $c$, metoda združevanja napovedi $select\_prediction$}  \\
	\textbf{Izhod: rekonstruirana primer $\hat{x}$} 
	\begin{algorithmic}[0]
		\For{$j = 1,\ldots,c$}
			\State prediction\_candidates $\gets$ [ ]
			\If{$x[j] = 1$}
				\State prediction\_candidates.append($\kappa$[$j$])
			\EndIf
		\EndFor
		\If{length(prediction\_candidates) > $0$}
			\State valid\_predictions $\gets$ [ ]
			\For{leaf in prediction\_candidates}
				\State valid\_predictions.append(leaf.prediction())
			\EndFor
			\State $\hat{x} \gets select\_prediction$(valid\_predictions) 
		\Else
			\State formula = [ ]
			\For{leaf in prediction\_candidates}
				\State path $\gets$ path\_to(leaf)
				\State formula.append($\lnot$ path)
			\EndFor
			\State $\hat{x} \gets DPLL\_example$(formula)
		\EndIf
		\State return($\hat{x}$)
	\end{algorithmic}
\end{algorithm}


% ====================  IMPLEMENTACIJA ==================== %

\section{Implementacija}

% Uvod v poglavje, pregled razdelkov.
Različico samokodirnika, ki smo jo predstavili v prejšnjem poglavju, smo implementirali v programskem jeziku Python.
% ===== CUT
Za primerjavo smo uporabili standardno implementacijo nevronskih mrež iz knjižnice keras (TODO: citat). % TODO: ali je to sploh res??? najbrž ne bo ostalo
Iz teh nevronskih mrež pa smo sestavili standarden samokodirnik, ki ga bomo uporabili za primerjavo z alternativno implementacijo.
% =====
V tem poglavju se bomo posvetili podrobnostim implementacije naše različice samokodirnika.
Najprej bomo opisali parametre, ki so uporabljeni v implementaciji, nato pa komponente, na katere je razdeljena koda.
Opisali bomo tudi različice samokodirnika, ki jih dobimo z uporabo nekaterih alternativnih različic funkcij, ki so sestavni deli samokodirnika.
Nato bomo našteli še nekaj možnih izboljšav implementacije samokodirnika.

% Komentar in utemeljitev za izbiro programskih jezikov, ki smo jih uporabili - python in R
Za Python smo se odločili, ker ima veliko število knjižnic, kar omogoča uporabo že implementiranih različic modelov strojnega učenja.
Koda napisana v Pythonu je v primerjavi z ostalimi programskimi jeziki sorazmerno kratka in pregledna in tudi zaradi tega je Python dobra izbira za prvotno implementacijo idej.
Uporabili smo implementacijo modelov strojnega učenja iz knjižnice sklearn.
% TODO: ali bo R uporabljen še za kej? najbrž. UPDATE
% Tudi programski jezik R ima na razpolago veliko število knjižnic in paketov za statistično analizo in strojno učenje.
Skripti za generiranje podatkovnih množic, ki jih uporabljamo pri vrednotenju samokodirnika, in izris grafov, ki prikazujejo rezultate testov, sta napisani v programskem jeziku R.
Za to smo se odločili zaradi velikega števila paketov in knjižnic za statistično analizo podatkov, ki jih ima R na razpolago.

V Pythonu smo uporabili predvsem dve večji knjižnici: keras, oz. TensorFlow, in sklearn.
% Komentar o knjižnicah, ki smo jih uporabili? npr.\ keras, sklearn
Keras je vmesnik za uporabo knjižnice TensorFlow, namenjen predvsem t.~i.\ globokemu učenju, oz. nevronskim mrežam. 
TensorFlow pa je popularna odprto kodna zbirka orodij za strojno učenje.
Za izgradnjo standardnega samokodirnika smo uporabili implementacijo nevronskih mrež iz knjižnice Keras.
Knjižnica sklearn, oz.\ scikit-learn je odprto kodna knjižnica, ki vsebuje nabor različnih orodij in modelov za strojno učenje.
V našem samokodirniku smo uporabili implementacijo odločitvenih dreves, naključnega gozda ter funkcije za računanje razdalje med primeri iz knjižnice sklearn.
(TODO: sklici na dokumentacijo knjižnic)

% TODO: odločitev; koliko je v tem poglavju smiselno pisati o nevronskih mrežah. Z opisi bi se morda posvetili predvsem naši alternativni implementaciji?

\subsection{Parametri}
\label{razdelek-parametri}

V tem razdelku bomo opisali pomembnejše parametre samokodirnika. 
Nastavljeni so na začetku skripte, da jih lahko uporabnik zlahka najde in po potrebi spreminja.
V poglavju o vrednotenju samokodirnika bomo tudi analizirali učinek spreminjanja večine teh parametrov na delovanje samokodirnika.
Med pomembnejše parametre samokodirnika spadajo sledeči.

\begin{itemize}
	\item \texttt{global\_seed}: Parameter, ki določi t.~i. ``seed'', ki se uporabi za simulacijo naključnosti.
	Postopek učenja in vrednotenja samokodirnika se večkrat ponovi, zato je global\_seed seznam, katerega dolžina je enaka številu iteracij.
	Tako ima postopek v vsaki iteraciji nov ``seed''. 
	Privzeta vrednost tega parametra je seznam $[1,2,\ldots,100]$.
	% TODO: nastavit parameter za seed, ki bo vseboval toliko elementov, kot je ponovitev vzorčenja/učenja, in ga tu opisati.

	\item \texttt{code\_size}: Parameter, ki označuje razsežnost zakodiranih primerov, oz.\ razsežnost kodirnega vektorja. 
	Veljavne vrednosti so naravna števila manjša ali enaka razsežnosti podatkovne množice.
	Primer, ko je \texttt{code\_size} enak ali večji od razsežnosti podatkovne množice, pa je načeloma trivialen.
	Parameter \texttt{code\_size} je v algoritmu \ref{algoritem-decode} označen z oznako $c$ in v algoritmu \ref{algoritem-find-encoding} označen z $d_{code}$. 
	(TODO: poenotiti oznake parametrov v različnih algoritmih)
	
	\item \texttt{diff\_th}: Parameter, ki določa dovoljeno mero podobnosti med listi, ki so vsebovani v kodirnem vektorju.
	Meja dovoljene podobnosti je uporabljena tako, kot je opisano v algoritmu \ref{algoritem-find-encoding}, kjer je označena s $t_{\mathit{sim}}$.
	Iz nabora kandidatov vsebovanih v kodirnem vektorju, ima poljuben par listov mero podobnosti praviloma manjšo od \texttt{default\_\-measure\_\-of\_\-diff}, 
	saj pri privzetem delovanju samokodirnika bolj podobnih parov v kodirni vektor ne vključimo.
	Privzeta vrednost parametra \texttt{diff\_th} je $0.1$. % TODO: določiti privzeto vrednost

	\item \texttt{rf\_size}: Parameter, ki opiše število odločitvenih dreves, ki sestavljajo naključni gozd. 
	V algoritmu \ref{algoritem-construct-RF} je ta parameter označen s $q$. 
	Večje število odločitvenih dreves izboljša natančnost gozda (TODO: citat?) in pričakujemo, da posledično izboljša kvaliteto samokodirnika.
	Privzeta vrednost parametra je $100$.

\end{itemize}

To so glavni (globalni) parametri pri delovanju samokodirnika, posamezne funkcije pa imajo seveda tudi druge (pomožne) parametre.
Pričakujemo, da bodo našteti parametri najmočneje vplivali na kvaliteto samokodirnika, zato bomo njihov vpliv preverili pri vrednotenju delovanja samokodirnika. 
Pomembnejše pomožne parametre bomo našteli pri opisu funkcij v naslednjem razdelku, pri testiranju pa jim ne nameravamo nameniti posebne pozornosti.


\subsection{Komponente}

% Opis komponent samokodirnika, npr.\ funkcije za iskanje primernih listov za kodo, itd. najbrž ne preveč podrobno.
\begin{figure}[h!]

	\begin{center}
	\includegraphics[width=\textwidth]{shema delovanja placeholder}
	\end{center}
	
	\caption{(začasna) Shema delovanja samokodirnika}
\end{figure}

Skripta, s katero smo implementirali samokodirnik, je razdeljena na komponente.
Nekatere komponente so glavni deli samokodirnika, druge pa so samo skupine dodatnih funkcij, ki smo jih umestili skupaj za boljšo organizacijo kode.
V tem razdelku bomo najprej našteli komponente iz katerih je skripta sestavljena, nato pa bomo pomembnejše komponente še podrobneje opisali.
Celotno kodo je možno pregledati v prilogi, sestavljena pa je iz sledečih komponent. % TODO: je to treba sploh omeniti?

\begin{itemize}
	\item skripta za generiranje podatkovnih množic: z njo generiramo množice za testiranje delovanja samokodirnika. 
	Implementirana je v R-ju, več pozornosti pa ji bomo namenili v poglavju o vrednotenju. % TODO: uskladiti s poglavjem o vrednotenju
	
	\item pomožne funkcije: nekatere dodatne funkcije, ki ne pripadajo direktno nobeni izmed ostalih komponent, 
	vendar poenostavijo implementacijo ostalih funkcij.

	\item kodirnik: funkcije, ki skupaj sestavljajo kodirnik, kot je opisan v algoritmu \ref{algoritem-encode}.

	\item funkcije za konstrukcijo kodirnega vektorja: 
	funkcije, ki so namenjene konstrukciji čim boljšega kodirnega vektorja in sledijo postopku opisanem v algoritmu \ref{algoritem-find-encoding}.

	\item dekodirnik: funkcije, ki skupaj sestavljajo dekodirnik, kot je opisan v algoritmu \ref{algoritem-decode}.

	\item funkcije za testiranje: funkcije, ki izvedejo postopek učenja samokodirnika ter ovrednotijo njegovo delovanje, ponavadi z več ponovitvami.

	\item funkcije za branje in zapis datotek: skupina funkcij, ki opravljajo branje podatkovnih množic iz datotek, zapisujejo rezultate in zapisnik (ang. log) poskusov, itd.

	\item skripta za risanje grafov: v R-ju napisana skripta, ki prebere datoteke z rezultati in ustvari graf rezultatov.
\end{itemize}

% vsebina opisa pri posamezni komponenti: namen, iz česa je sestavljeno, referenca na prejšnje dele naloge, če se ujema
% (TODO?: Pri vsakem odstavku se tudi našteje pripadajoče funkcije)

% cilj pri daljših opisih: bralcu dati vpogled v kodo, da se lahko malo bolje znajde, če želi, kaj preveriti v prilogi
% poudariti pomembne komponente/rešitve - ki se morda razlikujejo od ideje v algoritmih

% =================== KONSTRUKCIJA KODIRNEGA VEKTORJA =================== %
% Opis funkcije za konstrukcijo kodirnega vektorja. Opišemo, v kakšno strukturo shranimo kodiranje. Bolj splošno opišemo postopek.
Funkcije za konstrukcijo kodirnega vektorja okvirno sledijo postopku opisanem v algoritmu \ref{algoritem-find-encoding}.
Cilj postopka je konstruirati kodirni vektor, ki bo omogočil čim boljše delovanje samokodirnika, ki deluje na osnovi tega kodirnega vektorja. % TODO: čim bolj točen? boljši -> ???

V razdelku 3.3.3 smo kot mero kvalitete listov \textit{quality} določili delež listu pripadajočih primerov iz učne množice. 
Funkcija \texttt{max\_coverage} v danem odločitvenem drevesu poišče najbolj kvalitetne liste, tj. tiste, katerim pripada največje število primerov iz učne množice, in jih uredi glede na kvaliteto.
Vrne \texttt{n\_leaves} dolg seznam parov, ki vsebujejo delež listu pripadajočih primerov in indeks lista. 
Parameter \texttt{n\_leaves} je privzeto nastavljen na 1, kar pomeni, da funkcija vrne zgolj najbolj kvaliteten list iz odločitvenega drevesa.

Funkcija \texttt{find\_different\_candiates} (ali alternativno \texttt{find\_naive\_candidates}) za vsako drevo iz danega naključnega gozda pregleda najboljše liste, 
ki jih vrne funkcija \texttt{max\_coverage}, in jih združi v seznam \texttt{candidates}, za katerega želimo, da ob koncu postopka vsebuje čim boljše kandidate za kodirni vektor.
Posamezen list doda v seznam, če je bolj kvalitetni od nekega lista, ki je že vsebovan v seznamu in ni preveč podoben nobenemu izmed listov seznama.
To pomeni, da funkcija izračuna \texttt{code\_similarity} med novim listom in vsakim kandidatom v candidates - nov list dodamo samo v primeru, ko je njegova podobnost s poljubnim elementom seznama candidates manjša od \texttt{diff\_therence}.
Privzeta vrednost parametra \texttt{diff\_therence} je parameter \texttt{diff\_th}, ki je nastavljen na $0.1$.
Če je dolžina seznama že enaka želeni razsežnosti kodirnega vektorja, se nove liste doda tako, da se hkrati izbriše najmanj kvaliteten list vsebovan v seznamu.
% TODO: možnost izboljšave - način, kako se pregleda in preverja podobnost med listi. Morda bi loh najprej izbrali vse najboljše in od njih izločili podmnožico s čim manj podobnosti.

Funkcijo \texttt{find\_different\_candiates} nato ovijemo še s funkcijo \texttt{encoding\_naive} (ali alternativno \texttt{encoding}), da seznam najdenih kandidatov ''razpakira``.
Kandidate shrani v kodirni vektor in jim doda podatke, ki so potrebni v nadaljnji obdelavi. % TODO
Kodirni vektor shranimo v obliki seznama trojic, ki vsebujejo delež listu pripadajočih primerov, opis poti do lista in vrednost, ki jo list napove njemu pripadajočim primerom.

% TODO: prebrat in popravit, zmanjšat število odstavkov
% Sem spadajo funkcije: encoding, encoding\_naive, find\_naive\_candidates, find\_different\_candidates, max\_coverage

% TODO: omenit ekvivalente za nevronske mreže?


% =================== KODIRNIK =================== %
% Odstavek za opis kodirnika
% Sem spadajo funkcije: encode\_sample, encode\_set, check\_condition\_for\_sample

Funkcije za opis kodirnika so namenjene implementaciji kodirnika, kot je opisan v algoritmu \ref{algoritem-encode}.
Postopek kodiranja enega primera izvede funkcija \texttt{encode\_sample}, ki deluje s pomočjo pomožne funkcije \texttt{check\_condition\_for\_sample}.
Pomožno funkcijo \texttt{check\_condition\_for\_sample} uporabimo, da preveri, ali logični pogoj drži za dan primer iz podatkovne množice.
Funkcija \texttt{encode\_set} z uporabo \texttt{encode\_sample} zakodira celo podatkovno množico primerov, da za uporabnika poenostavi kodiranje podatkov.

% =================== DEKODIRNIK =================== %

% TODO: Odstavek za opis dekodirnika
% Sem spadajo funkcije: decode\_sample, decode\_set, 
% feature\_in\_list, prune\_formula, choose\_literal, replace\_literal, check\_for\_unit\_clause, check\_for\_pure\_literal, dpll, find\_negation\_candidate

Dekodirnik implementiramo s funkcijo \texttt{decode\_sample} po postopku, ki je opisan v algoritmu \ref{algoritem-decode}.
Pri dekodiranju se držimo načela, ki smo ga opisali v poglavju o dekodirniku.
Zakodiranim primerom, ki pripadajo vsaj enemu listu iz kodirnega vektorja, napovemo vrednost, ki bi jo ta list napovedal pripadajočim primerom.
Če najdemo v kodirnem vektorju več primernih listov, uporabimo napoved zadnjega najdenega, 
saj pri združevanju napovedi več listov nismo opazili izboljšave natančnosti in je to iz vidika implementacije najbolj preprosto.
Pri primerih, ki ne pripadajo nobenemu listu iz kodirnega vektorja, uporabimo DPLL algoritem. % TODO sklic na razdelek 3.3.3 (?)
Pomožna funkcija \texttt{find\_negation\_candidate} inicializira funkcijo \texttt{dpll}, ki z uporabo pomožnih funkcij izvede postopek DPLL algoritma. % in vrne primer, ki ustreza rezultatu algoritma.
Rezultat DPLL algoritma funkcija \texttt{find\_negation\_candidate} nato uporabi, da poišče in vrne primer, ki se ujema z rezultatom algoritma.
Za bolj enostavno uporabo s strani uporabnika funkcija \texttt{decode\_set} dekodira celo množico zakodiranih primerov hkrati z uporabo funkcije \texttt{decode\_sample}.

% TODO: odločit se ali se vse DPLL funkcije uvrstimo k dekodirniku

Pomožne funkcije se delijo na par podskupin, ki imajo skupen namen:
% ekstra stavek ali dva opisa
\begin{itemize}
	\item funkcije za tiskanje izpisov: Sem spadata \texttt{print\_path}, ki za v urejeni obliki izpiše pot do izbranega vozlišča v drevesu, in 
	\texttt{print\_encoding}, ki v urejeni obliki izpiše kodirni vektor z dodatnimi podatki o deležu pripadajočih primerov in napovedih posameznih listov.

	\item implementacija DPLL algoritma: Sem spadajo funkcije \texttt{dpll}, \texttt{feature\_in\_list}, \texttt{prune\_formula, choose\_literal}, \texttt{replace\_literal}, \texttt{check\_for\_unit\_clause} in \texttt{check\_for\_pure\_literal}.
	
	\item funkciji za poiskati vrednost, ki jo pripadajočim primerom napove določen list odločitvenega drevesa: \texttt{leaf\_label} in \texttt{convert\_labels}.
	
	\item funkcije za računanje mere podobnosti listov $sim$ (uporabljene v algoritmu \ref{algoritem-find-encoding}): 
	Sem spadata funkciji \texttt{node\_to\_vector} in \texttt{code\_similarity}.
	Funkcija \texttt{node\_to\_vector} izbrano vozlišče odločitvenega drevesa zakodira s pripadajočimi primeri iz podatkovne množice, % TODO: sklic na opis tega kodiranja v prejšnjem poglavju % TODO: node\_to\_vector, code\_similarity
	funkcija \texttt{code\_similarity} pa izračuna mero podobnosti dveh danih listov.
	
	\item funkcije za obdelavo poti: Sem spadata \texttt{path\_to}, ki v danem odločitvenem drevesu poišče pot do izbranega vozlišča, 
	in \texttt{find\_path}, ki je pomožna funkcija namenjena lažji implementaciji funkcije \texttt{path\_to}.
\end{itemize}

% ===================

\subsection{Različice algoritma}

% Uvod/pregled razdelka (kolikor alternativ bo ostalo v končni implementaciji - ali sploh kakšna razen pri iskanju kodiranja?).
V tem razdelku bomo opisali dele samokodirnika, pri katerih je implementiranih več različnih funkcij z enakim namenom.
Povedali bomo, katere funkcije so v delovanju privzete in zakaj je lahko uporabna alternativna implementacija.
Različice funkcij bomo tudi kratko opisali in poudarili razlike med njimi.

Privzeto je za konstrukcijo kodirnega vektorja uporabljena funkcija \texttt{encoding\_naive},
implementirani pa sta dve različni funkciji, ki konstruirata kodirni vektor:

% TODO: katero privzeto uporabljamo???
\begin{itemize}
	\item \texttt{encoding\_naive}: funkcija, ki naivno pregleda kandidate listov za kodirni vektor. 
	Da je delovanje hitrejše, pregleda zgolj najbolj kvaliteten list iz vsakega odločitvenega drevesa, ki ga nato potencialno doda v kodirni vektor.

	\item \texttt{encoding}: funkcija, ki liste pregleda manj naivno.
	Ker lahko funkcija \texttt{encoding\_naive} veliko potencialnih kandidatov pri pregledovanju izpusti, bi lahko dobili boljši rezultat z upoštevanjem več kandidatov.
	V drevesih, katerih najbolj kvaliteten list je dovolj dober za vključiti v kodirni vektor, pregleda funkcija \texttt{encoding} tudi drugi najboljši list.
	Postopek nadaljuje na podoben način in za vsak list, ki ga vključi v kodirni vektor, preveri, ali je tudi po kvaliteti naslednji list dovolj dober kandidat.
	Če list ni dovolj kvaliteten za vključiti v kodirni vektor, tudi drugi manj kvalitetni listi ne bojo, torej se lahko pregled drevesa zaključi.
	Na tak način so v kodirni vektor res vključeni vsi po kvaliteti najboljši kandidati.
\end{itemize}

Pri konstrukciji kodirnega vektorja se uporabi pomožna funkcija, ki pregleda naključni gozd in izbere seznam listov, ki so dobri kandidati.
Za iskanje kandidatov sta implementirani dve različni funkciji, privzeto pa se uporablja funkcija \texttt{find\_different\_candidates}.

\begin{itemize}
	\item \texttt{find\_naive\_candidates}: pregleda liste dreves naključnega gozda in ustvari seznam najbolj kvalitetnih kandidatov.
	Deluje hitro vendar naivno, ker upošteva zgolj najbolj kvaliteten list vsakega odločitvenega drevesa.
	Poleg tega lahko v seznam kandidatov doda med seboj zelo podobne liste, saj ne preverja njihove medsebojne mere podobnosti.

	\item \texttt{find\_different\_candidates}: pregleda liste dreves naključnega gozda, 
	pri dodajanju kandidatov pa preveri mero podobnosti, da med kandidate ne vključi preveč podobnih listov.
	Nov list doda v seznam kandidatov samo, če ima dovolj majhno mero podobnosti z vsemi že vključenimi kandidati.
	Tako v seznamu kandidatov ni odvečnega prekrivanja.
\end{itemize}

% TODO: opomba da iskanje kodirnih vektorjev ni exhaustive??? vsaj ponavadi definitivno ne

% ===================

\subsection{Možne izboljšave}
\label{mozne-izboljsave}

% TODO: premislit očitne pomanjkljivosti in možne (ambiciozne) nadgradnje

Ta razdelek je namenjen kratkemu pregledu možnih izboljšav našega samokodirnika.
V implementaciji bi se s pozornim premislekom in uporabo bolj optimalnih metod zagotovo dalo izboljšati prostorsko in časovno zahtevnost.
S tem se bomo ukvarjali v prihodnosti, če bomo samokodirnik želeli uporabiti v praksi.
Obstaja tudi nekaj drugih idejnih izboljšav samokodirnika, ki bi potencialno lahko izboljšale delovanje.

% Izboljšava mere za vrednotenje listov $quality$ iz algoritma \ref{algoritem-find-encoding} s tem, da upoštevamo lokalno natančnost napovedi listov.
Način na katerega definiramo mero kvalitete listov, ki so kandidati za kodirni vektor, tj. količino $quality$ iz algoritma \ref{algoritem-find-encoding},
bi lahko priredili, da upošteva lokalno natančnost napovedi listov.
Domnevamo, da bi z vključevanjem čim bolj natančnih listov v kodirni vektor lahko dosegli boljšo natančnost samokodirnika.
Za implementacijo tega bi kot mero kvalitete listov izbrali formulo, ki združuje trenutno mero, tj. delež pripadajočih primerov, in lokalno natančnost lista.
Preizkusiti bi bilo vredno tudi mero, ki upošteva zgolj lokalno natančnost lista.

% Drugi načini pregledovanja kandidatov za kodirni vektor. % wtf sploh hočem s tem? xD
% TODO
Spremenili bi lahko tudi način na katerega uporabimo mero podobnosti med listi, ki so kandidati za kodirni vektor.
Trenutno se list v kodirnem vektorju zamenja z novim, boljšim kandidatom zgolj, če nov list nima previsoke mere podobnosti s katerimkoli že vključenim listom.
Tak pristop je ``greedy'' in delovanje samokodirnika bi lahko morda izboljšali z bolj temeljito primerjavo podobnosti.
V tem primeru bi se najprej izbral nabor določenega števila najbolj kvalitetnih listov v gozdu.
Nato pa bi iz tega nabora želeli izbrati podmnožico kandidatov, ki bi imeli med seboj čim manjšo prekrivanje - torej čim manjšo mero podobnosti.
Tako izbrano podmnožico listov bi uporabili kot kodirni vektor.

Samokodirnik bi z nekaj dela lahko usposobili tudi za delovanje na slikah.
Zaenkrat v ta namen še ni bil testiran.

% ==================== VREDNOTENJE  ==================== %

\section{Vrednotenje}

% Opis testiranja in rezultatov.
V tem poglavju bomo preizkusili delovanje našega samokodirnika na različnih primerih in ga ovrednotili.
Cilji testiranja so:
\begin{itemize}
	\item Preveriti natančnost, ki jo dosega samokodirnik pri različnih vrednostih glavnih parametrov opisanih v razdelku \ref{razdelek-parametri}, 
	in določiti čim boljše privzete vrednosti za te parametre.

	\item Primerjati natančnost, ki jo dosega naš samokodirnik z natančnostjo standardnih samokodirnikov iz nevronskih mrež.

	\item Interpretirati rezultate, ki jih dobimo z našim samokodirnikom, za boljše razumevanje nejgovega delovanja.
\end{itemize}

% zapis ciljev:
% izvesti param tuning za pomembne parametre - da ugotovimo, kako deluje samokodirnik najbolje
% interpretacija rezultatov - ali lahko ugotovimo kej posebnega o vmesni množici, imamo kakšen vpogled v delovanje? % TODO: cilj je bil, da ni black box, to moramo premislit
% primerjava rekonstrukcijske napake z samokodirniki iz nevronskih mrež.

\subsection{Metodologija}
% good question tbh

% poiščemo (konstruiramo) dobro podatkovno množico.
Teste izvajamo na podatkovnih množicah, za katere vemo, da se jih da opisati v prostoru manjše razsežnosti. (TODO: citat) % TODO: kako to že imenujemo???
v naslednjem razdelku (TODO: sklic) jih bomo podrobno definirali in opisali, kako jih konstruiramo.


% definiramo rekonstrukcijsko napako % smo jo že prej? preverit povezavo z osnovnimi definicijami
\begin{definicija}
	Naj bo $\omega_p$ podatkovna množica razsežnosti $p$ in naj bo $m: \omega_p \rightarrow \omega_p$ samokodirnik.
	\emph{Rekonstrukcijska napaka} samokodirnika $m$ na množici $\omega_p$ je funkcija napake s sledečim predpisom:
	\[
		Err(m,\omega_p) = \sqrt{\frac{1}{|\omega_p|} \sum_{x \in \omega_p} (m(x)-x)^2}.
	\]
\end{definicija}	

%TODO: popravit definicijo funkcije napake, da bo rekonstrukcijska napak uradno funkcija napake?
% Rekonstrukcijska napaka samokodirnika na množici $X_{neki}$ je error function (todo: sklic na def) na izbrani množici, kjer je cilja spremenljivka enaka vhodnim spremenljivkam.

% na množici izberemo učno in testno množico.
% na testni množici naučimo samokodirnik in ovrednotimo njegovo natančnost na testni množici.
% postopek ponovimo večkrat (stokrat), in rezultate shranjujemo.
% Na koncu izračunamo ter shranimo povprečno rekonstrukcijsko napako ter standardno deviacijo.

% bi bilo treba napisat imena za učno in testno množico???
Podatkovno množico razdelimo na dva dela - na učno množico in testno množico.
Denimo, da množica $\omega_p$ vsebuje $n$ primerov.
Množico razdelimo tako, da $n$-krat enakomerno naključno izberemo indeks $i \in \N$ iz nabora $\{1,2,\ldots,n\}$.
Kopijo primera, ki je v podatkovni množici na $i$-tem mestu, dodamo v učno množico in označimo, da je primer vsebovan v učni množici.
Primere, ki ob koncu postopka niso vsebovani v učni množici, dodamo v testno množico.

% Učni množico uporabimo, da naučimo naključni gozd.
% Iz naključnega gozda nato konstruiramo kodirni vektor z postopkom iz (TODO: sklic na algoritem).
% Na osnovi tega kodirnega vektorja zakodiramo podatke iz testne množice in jih nato dekodiramo (TODO: sklic).
% Izračunamo rekonstrukcijsko napako in jo shranimo.
Z učno množico naučimo model naključnega gozda. % TODO: naučimo - natreniramo?
S postopkom iz algoritma \ref{algoritem-find-encoding} na osnovi tega naključnega gozda konstruiramo kodirni vektor.
Ta kodirni vektor nato uporabimo kot argument za kodirnik iz algoritma \ref{algoritem-encode} in dekodirnik iz algoritma \ref{algoritem-decode}, ki skupaj tvorita naš samokodirnik.
Izračunamo rekonstrukcijsko napako samokodirnika na testni množici in jo shranimo.

Ker želimo bolj splošen rezultat, ta postopek ponovimo stokrat z različnimi naključnimi ``seed-i''.
Ko zaključimo z vsemi iteracijami, izračunamo povprečje rekonstrukcijskih napak in standardno deviacijo.
Rezultate in parametre postopka shranimo v datoteke za beleženje in nadaljnjo obdelavo.

% TODO: opisat še postopek za teste z nevronskimi mrežami?

\subsection{Podatkovne množice}
% TODO: prebrati literaturo
% TODO: preveriti definicije podatkovne množice itd. da vidimo, če se ta razdelek ujemaz  našo formulacijo

% uvod
Za učenje samokodirnikov želimo množico, ki se jo da predstaviti v prostoru manjše razsežnosti.
V ta namen bomo izbrali množico primerov v prostoru manjše razsežnosti in jih s transformacijo preslikali v prostor višje razsežnosti.
Ta postopek lahko imenujemo konstrukcija spremenljivk, podrobneje pa je opisan v~\cite[razdelek\ 10.3]{flach2012machine}.

% formulacija
Naj bo $q \in \N$ razsežnost prvotnega prostora, ki ga imenujemo tudi \emph{skriti prostor} (ang. ``latent space'')
in $p > q$ naravno število, ki je razsežnost večjega prostora.
Naj bo v matriki $Z \in \R^{n \times q}$ zapisanih $n$ primerov iz prvotnega prostora.
Naj bosta $W \in \R^{q \times p}$ in $X \in \R^{n \times p}$ taki matriki, da velja:
\[
	X = Z \cdot W.
\]
Matrika $W$ je transformacijska matrika, ki primere preslika iz skritega prostora razsežnosti $q$ v večji prostor razsežnosti $p$.
V matriki $X$ pa so zapisani preslikani primeri, predstavlja podatkovno množico razsežnosti $p$ z $n$ primeri.

% primer za razumevanje
Preprost praktičen primer podatkovne množice transformirane iz skritega prostora bi bila npr. množica uporabnikov aplikacije za gledanje filmov in njihove preference.
Matriko $X$ lahko razumemo kot zapis preferenc uporabnikov, kjer so spremenljivke posamezni filmi, in je s boolovimi vrednostmi zapisano, ali je bil uporabniku film všeč.
V tem primeru bi spremenljivke skritega prostora predstavljale žanre filmov, matrika $Z$ pa bi opisala, kateri žanri so všeč kateremu uporabniku.
Transformacijska matrika $W$ definira povezavo med skritim in razširjenim prostorom in bi v tem primeru vsebovala podatke o tem, kater film pripada katerim žanrom.

% dodatni podatki o konstrukciji
Podatkovno množico za testiranje konstruiramo tako, da najprej konstruiramo matriko $Z$ primerov v skritem prostoru.
Pri primeru, kjer $q$ ni prevelik, matriko konstruiramo tako, da naštejemo vse različne kombinacije vektorjev dolžine $q$, ki vsebujejo boolove vrednosti.
Nato naključno generiramo še transformacijsko matriko $W$ in ju pomnožimo, da dobimo podatkovno množico $X$ razsežnosti $p$, ki ima rang velikosti kvečjemu $q$.
Pri konstrukciji lahko določimo še omejitev \textit{qs} števila enic v vrsti/stolpcu, da sta matriki dovolj ``sparse''.
V prej opisanem primeru bi to pomenilo, da lahko film pripada največ \textit{qs} žanrom in da je uporabniku všeč kvečjemu \textit{qs} žanrov.

\subsection{Rezultati}
% === PODATKI ZA GAMMA 1 === %
% avg_err = 0.5391602
% avg_std = 0.03706497

% === PODATKI ZA GAMMA 0.99 === %
% avg_err = 0.5380129
% avg_std = 0.03673274

% === PODATKI ZA GAMMA 0.65 === %
% avg_err = 0.5370301
% avg_std = 0.04067136

% Opišemo vrstni red testiranja/pregled
% Teste smo izvajali v vrstnem redu, kjer smo najprej želeli izvesti t.i. "parameter tuning" in ugotoviti dobre nastavitve ključnih parametrov.
% Zanimalo nas je tudi to, kako posamezen parameter vpliva na delovanje itd.
% Po tem, ko smo določili dobre vrednosti parametrov smo izvedli še več splošnih testov delovanja in natančnost primerjali s standardnimi samokodirniki.
S testi smo najprej želeli preveriti vpliv posameznih parametrov na delovanje in rekonstrukcijsko napako samokodirnika.
Za pomembnejše parametre smo želeli tudi določiti čim boljše privzete vrednosti.
TODO: opis na kakšni množici smo delali param tuning.
Nato smo izvedli še več splošnih testov delovanja, pri katerih smo primerjali rekonstrukcijsko napako našega samokodirnika s standardnimi samokodirniki in ovrednotili njegovo delovanje.


% ====== PARAMETER TUNING ====== %

% - grafi in rezultati za param tuning -

% Določimo čim bolj optimalne parametre, s katerimi nadaljujemo poskuse.

Najprej smo želeli določiti dobre vrednosti parametra $\gamma$ mere kvalitete $\rho$, ki smo jo definirali v razdelku \ref{mera-kvalitete}.
Teste smo najprej izvajali s privzetim parametrom \texttt{code\_size} $= 7$. % TODO: dopolniti s podatki o množici/privzetih parametrih
Začeli smo z grobim preverjanjem vrednosti, kjer smo $\gamma$ testirali z intervalom vrednosti $0,05$.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{images/rough gamma tuning.png}
  % \caption[caption za v kazalo]{Dolg caption pod sliko}
	\caption[Pregled rekonstrukcijske napake glede na $\gamma$.]{Graf prikazuje povprečno rekonstrukcijsko napako našega 
	samokodirnika v odvisnosti od vrednosti parametra $\gamma$ na intervalu $[0,\ 1]$, kjer smo teste izvajali na interval vrednosti $0,05$. 
	TODO: dopisati vrednosti parametrov pri poskusu?}
	\label{fig:gamma_rough}
\end{figure}

Iz grafa \ref{fig:gamma_rough} vidimo jasen prehod, da se rekonstrukcijska napaka začne manjšati okoli vrednosti $\gamma=0,5$, 
od vrednosti $\gamma=0,6$ naprej pa napaka dosega najnižje vrednosti.
Če se spomnimo definicije mere kvalitete $\rho$ iz razdelka \ref{mera-kvalitete}, opazimo, da je napaka manjša, 
kadar mera kvalitete bolj upošteva delež listu pripadajočih primerov kot lokalno natančnost.
V intervalu vrednosti $\gamma \in [0.6,\ 1]$ smo natančnost samokodirnika preverili še bolj natančno s testi z intervalom vrednosti $0,01$ za $\gamma$.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{images/fine gamma tuning.png}
  % \caption[caption za v kazalo]{Dolg caption pod sliko}
	\caption[Podrobnejši graf napake glede na $\gamma$.]{Graf prikazuje povprečno rekonstrukcijsko napako našega 
	samokodirnika v odvisnosti od vrednosti parametra $\gamma$ na intervalu $[0.6,\ 1]$, kjer smo teste izvajali na interval vrednosti $0,01$. 
	TODO: dopisati vrednosti parametrov pri poskusu?}
	\label{fig:gamma_fine}
\end{figure}

% TODO: dodati axis labels na slike grafov!!!!!!!!!
% Iz rezultatov vidimo, da sta v tem primeru najboljši vrednosti parametra gamma 0.65 in 0.99, 
% dobra pa je tudi vrednost 1, ki nas zanima tudi zato, ker predstavlja bolj enostavno mero kvalitete.
% Te tri vrednosti smo dodatno analizirali in primerjali med seboj, tako da smo teste z njimi pognali za vse code\_size razsežnosti.
Na grafu \ref{fig:gamma_fine} opazimo, da je rekonstrukcijska napaka minimalna pri argumentih $\gamma=0,65$ in $\gamma=0,99$.
Napak je sorazmerno majhna tudi pri $\gamma=1$, ta vrednost pa je posebej zanimva, saj se mera kvalitete v tem primeru poenostavi.
Natančnost samokodirnika pri teh treh vrednostih $\gamma$ smo dodatno analizirali s testiranjem pri različnih nastavitvah razsežnosti \texttt{code\_size}.
Zanima pa nas tudi pri kateri razsežnosti je samokodirnik najbolj natančen.

\begin{figure}[h]
	\centering
	\subfigure[]{\includegraphics[width=0.3\textwidth]{images/gamma065 code size plot.png}}
	\subfigure[]{\includegraphics[width=0.3\textwidth]{images/gamma099 code size plot.png}}
	\subfigure[]{\includegraphics[width=0.3\textwidth]{images/gamma1 code size plot.png}}
  % \caption[caption za v kazalo]{Dolg caption pod sliko}
	\caption[Tri grafi napake glede na \texttt{code\_size}]{Shema prikazuje povprečno rekonstrukcijsko napako samokodirnika glede na razsežnost \texttt{code\_size}.
		(a) natančnost samokodirnika pri $\gamma = 0.65$ 
		(b) natančnost samokodirnika pri $\gamma = 0.99$ 
		(c) natančnost samokodirnika pri $\gamma = 1$}
	\label{fig:triple_code_size}
\end{figure}

% Opazimo, da so v splošnem nekatere razsežnosti boljše, 1 in 15 sta trivialni, nas ne zanima tok.
% Posebej izpostavimo razsežnost, s katero je množica dejansko generirana.
% Zanima nad parameter, pri katerem dosegamo dobre razsežnosti, pričakujemo, da je boljša natančnost pri večjih dimenzijah.
Iz grafov v figuri \ref{fig:triple_code_size} razberemo, da se rekonstrukcijska napaka z večanjem razsežnosti \texttt{code\_size} praviloma manjša.
Napaka pa je dosegla minimum pri vrednostih parametra od $12$ do $15$.
Noben izmed grafov ni pri vseh vrednostih boljši od ostalih dveh, 
zato želimo primerjati tudi povprečno napako in bomo za primerjavo delovanja pri različnih vrednostih parametra $\gamma$ uporabili še drugačen prikaz podatkov.

% TODO: katere dimenzije je vredno upoštevati???
\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{images/test_brki_plot_brez15in1.png}
  % \caption[caption za v kazalo]{Dolg caption pod sliko}
	\caption[Graf z brki.]{Shema prikazuje porazdelitev povprečne rekonstrukcijske napake pri različnih parametrih $\gamma$,
	kjer smo iz rezultatov izpustili trivialna primera \texttt{code\_size} $\in \{1,15\}$.
	Zgornji in spodnji rob navpičnih črt predstavljata maksimalno in minimalno doseženo vrednost napake,
	škatla predstavlja interval v katerem je vsebovana (srednja) polovica doseženih vrednosti
	in odebeljena vodoravna črta pa predstavlja mediano.}
	\label{fig:boxplot}
\end{figure}

% Vidimo, da v povprečju najboljšo natančnost dosegamo pri parametru 0.65.
% Rezultati pa izpadejo tudi bolj konsistentni, saj je dobra pri višjih razsežnostih (7-15), ki jih bomo najverjetneje večinoma uporabljali.
% Naivno je pričakovat, da lahko razsežnost množice skrčimo denimo na 3 dimenzije in ohranimo večino podatkov.
Iz grafa \ref{fig:boxplot} razberemo, da samokodirnik najmanjšo napako doseže pri $\gamma=0,65$, vendar imajo rezultati v tem primeru tudi največjo varianco.
Opazimo tudi, da so rezultati vseh treh primerov primerljivi, najslabši pa so načeloma pri $\gamma=1$, kjer je mediana napake najvišja.
Za splošno uporabo bomo izbrali $\gamma=0,99$, ki ima najboljše rezultate sicer nekoliko slabše kot $\gamma=0.65$, 
vendar ima pri rezultatih precej manjšo varianco in ima manjšo mediano rezultatov.
Če primerjamo še grafe iz figure \ref{fig:triple_code_size}, opazimo, da bi se nastavitev $\gamma=0,65$ splačalo uporabljati v primerih, 
ko je parameter \texttt{code\_size} dovolj velik, npr.\ pri tej podatkovni množici večji ali enak $10$.

% do sedaj smo "uporabljali" parameter 1, kar pomeni, da se mere razlike ne uporablja (razen, da ne menjamo kandidatov v kodirnem vektorju z enakimi). 
% v resnici je bilo to ponesreči, ampak OK

Do sedaj smo uporabljali nastavitev \texttt{diff\_th} $=1$.
To pomeni, da podobnosti med kandidati v kodirnem vektorju nismo zares upoštevali.
\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{images/measure of diff plot.png}
  % \caption[caption za v kazalo]{Dolg caption pod sliko}
	\caption[Graf napake glede na mero razlike.]{Graf prikazuje povprečno rekonstrukcijsko napako v odvisnosti od mere razlike \texttt{diff\_th.}}
	\label{fig:measure_of_diff}
\end{figure}
Na grafu \ref{fig:measure_of_diff} je prikazana povprečna rekonstrukcijska napaka v odvisnosti od parametra \texttt{diff\_th}.
Opazimo, da je minimalna napaka dosežena pri vrednosti $0,35$, vendar je dobra na zelo majhnem intervalu.
Napaka je pri vrednostih od $0$ do $0,3$ konstantna in sklepamo, da to pomeni, da je v tem primeru kodirni vektor sestavljen i z prvih izbranih kandidatov
- do zamenjave kandidatov ne pride, saj so vsi naslednji kandidati ``preveč'' podobni že vključenim.
Pri vrednostih od $0,5$ do $0,9$ je napaka manjša kot pri $1$, vendar je razlika zelo majhna.

Glede na zelo majhen interval, kjer je napaka blizu lokalnemu minimumu, ki je verjetno odvisen tudi od podatkovne množice, in sorazmerno majhne razlike v natančnosti pri drugih argumentih se zdi tudi \texttt{diff\_th} $=1$ sprejemljiva izbira argumenta.
Sklepamo, da bi morali način filtriranja preveč podobnih primerov izboljšati, da bi s tem parametrom dosegli boljšo natančnost.
Možne ideje za nadgradnjo tega dela algoritma so zapisane v razdelku \ref{mozne-izboljsave}.
% TODO: dopisati ekstra ideje v razdelek za izboljsave

% To bi se dalo morda izboljšati z izboljšanjem algoritma, kar je zagotovo možnost za nadaljne izboljšave, npr:

% \begin{itemize}
% \item pri ugotavljanju podobnosti z elementi kodirnega vektorja - 
% če je nov kandidat zelo podoben kakšnemu že vsebovanemu in bolj kvaliteten, bi ju lahko zamenjali. Zaenkrat prepodobne kandidate samo odvržemo.

% \item popolnoma spremenimo postopek - naberemo preveliko število kandidatov, ki so najbolj kvalitetni.
% Šele nato preverjamo, koliko so si med seboj podobni in izmed medseboj podobnih vn mečemo slabše kandidate.
% Tako ožimo nabor kandidatov, dokler jih ne ostane zgolj želeno število.
% \end{itemize}

% Zaenkrat tega parametra ne uporabljamo, dokler se implementacija algoritma ne izboljša? maybe

\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{images/n trees plot.png}
  % \caption[caption za v kazalo]{Dolg caption pod sliko}
	\caption[Graf natančnosti glede na \texttt{rf\_size}]{Shema prikazuje povprečno rekonstrukcijsko napako glede na število odločitvenih dreves \texttt{rf\_size} v naključnem gozdu.}
	\label{fig:n_trees}
\end{figure}

% Vidimo, da večanje števila dreves lahko izboljša natančnost, vendar to ni zagotovljeno.
% Morda je kriva neoptimalnost algoritma, ki iz večjega nabora kandidatov/listov ne more zagotovo izbrati boljšega kodirnega vektorja.
% Glede na to, da večje vrednosti parametra zahtevajo več procesorskega časa in rezultat ni zagotovljeno boljši, bomo ta parameter pustili takšen kot je bil t.i. 100.

Na shemi \ref{fig:n_trees} je prikazan graf rekonstrukcijske napake v odvisnosti od števila dreves v naključnem gozdu \texttt{rf\_size}.
Opazimo, da večanje parametra lahko zmanjša napako, vendar to ni zagotovljeno.
Podobno, kot pri prejšnjem primeru lahko predpostavimo, da samokodirnik ne deluje optimalno, saj ima pri večjem številu dreves na razpolago več kandidatov za kodirni vektor, vendar ne uspe zanesljivo izbrati boljšega nabora.
Tudi to bi se lahko morda izboljšalo z nadgradnjo algoritma.
Glede nato, da večje število dreves zahteva vse več procesorskega časa in spomina, boljša rezultat pa ni zagotovljen, bomo ta parameter privzeto pustili pri enaki vrednosti kot do sedaj, t.~j. \texttt{rf\_size} $=100$.

% OSTALO TESTIRANJE

TODO: Testi v primerjavi z nevronskimi mrežami, na več različnih množicah/primerih.

% TODO: interpretacija rezultatov - vpogled v kodiranje???

% TODO: a bi rabil analizo, kok časa to rabi?

% ==================== ZAKLJUČEK ==================== %
\section{Zaključek}  



% ================================================================================================================================================================== %
% ================================================================================================================================================================== %


\subsection{Kako narediti stvarno kazalo}
Dodate ukaze \verb|\index{polje}| na besede, kjer je pojavijo, kot tukaj\index{tukaj}.
Več o stvarnih kazalih je na voljo na \url{https://en.wikibooks.org/wiki/LaTeX/Indexing}.

% \subsection{Navajanje literature}
% Članke citiramo z uporabo \verb|\cite{label}|, \verb|\cite[text]{label}| ali pa več naenkrat s
% \verb|\cite\{label1, label2}|. Tudi tukaj predhodno besedo in citat povežemo z nedeljivim presledkom
% $\sim$. Na primer~\cite{chen2006meshless,liu2001point}, ali pa \cite{kibriya2007empirical}, ali pa
% \cite[str.\ 12]{trobec2015parallel}, \cite[enačba (2.3)]{pereira2016convergence}.
% Vnosi iz \verb|.bib| datoteke, ki niso citirani, se ne prikažejo v seznamu literature, zato jih
% tukaj citiram.~\cite{vene2000categorical}, \cite{gregoric2017stopniceni}, \cite{slak2015induktivni},
% \cite{nsphere}, \cite{kearsley1975linearly}, \cite{STtemplate}, \cite{NunbergerTand}.

% Literatura:
% Primer navajanja na http://www.fmf.uni-lj.si/storage/24240/LiteraturaM.pdf,
% ampak bi moral stil poskrbeti za vse. Reference se uredijo po abecedi.
% Če nobena izbira izmed @book, @atricle,... ni ok, potem se lahko vse napiše v
% @misc pod note={} in deluje tako kot normalen LaTeX.
% Komentar v bib datoteki se naredi samo s parom { }
% Za urejanje literature avtor priporoča program Jabref, ki zna tudi avtomatsko
% okrajšati imena revij. Za pravilno sortiranje vnosov brez avtorja, uporabite
% polje key={ }, kot v primeru.
% V primeru napak ustvarite issue na GitHubu ali pišite na jure.slak@fmf.uni-lj.si.
\cleardoublepage                           % na desni strani
\phantomsection                            % da prav delujejo hiperlinki
\addcontentsline{toc}{section}{\bibname}   % dodajmo v kazalo
\bibliographystyle{fmf-sl}                 % uporabljen stil je v datoteki fmf-sl.bst, na voljo tudi angleška verzija
\bibliography{\literatura}                 % literatura je v datoteki, definirani na začetku
% TeXStudio zmede \ zgoraj, tako da lahko notri napišeš dejansko ime .bib datoteke, če ti
% ne delajo predlogi citatov.

% Za stvarno kazalo
\cleardoublepage                           % na desni strani
\phantomsection                            % da prav delujejo hiperlinki
\addcontentsline{toc}{section}{\indexname} % dodajmo v kazalo
\printindex

\end{document}
